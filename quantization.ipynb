{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30dcf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy.linalg as LA\n",
    "import torch.quantization\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import categorical_gumbel_softmax_sampling, categorical_softmax, get_acc_and_bac, continuous_sigmoid_bound, Timer\n",
    "import torch\n",
    "from attacks.initializations import _uniform_initialization, _gaussian_initialization, _mean_initialization, \\\n",
    "    _dataset_sample_initialization, _likelihood_prior_sample_initialization, _mixed_initialization, \\\n",
    "    _best_sample_initialization\n",
    "from attacks.priors import _joint_gmm_prior, _mean_field_gmm_prior, _categorical_prior, _categorical_l2_prior, \\\n",
    "    _categorical_mean_field_jensen_shannon_prior, _continuous_uniform_prior, _theoretical_optimal_prior, \\\n",
    "    _theoretical_typicality_prior, _theoretical_marginal_prior, _theoretical_marginal_typicality_prior\n",
    "from attacks.inversion_losses import _weighted_CS_SE_loss, _gradient_norm_weighted_CS_SE_loss, _squared_error_loss, _cosine_similarity_loss\n",
    "from attacks.ensembling import pooled_ensemble\n",
    "from collections import OrderedDict\n",
    "from models import MetaMonkey\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import os\n",
    "import multiprocessing\n",
    "from defenses import dp_defense\n",
    "from fair_loss import FairLoss\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import attacks\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import match_reconstruction_ground_truth, Timer, post_process_continuous\n",
    "from attacks import train_and_attack_fed_avg\n",
    "from models import FullyConnected\n",
    "from datasets import ADULT\n",
    "import pickle\n",
    "from attacks import calculate_random_baseline\n",
    "from torch.quantization import QuantStub, DeQuantStub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193efdf3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b821a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce2c8b5",
   "metadata": {},
   "source": [
    "# Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e5395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31e4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    A linear layer followed by a ReLU activation layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(LinReLU, self).__init__()\n",
    "        self.linear = nn.Linear(in_size, out_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layers = nn.Sequential(self.linear, self.relu)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.linear.reset_parameters()\n",
    "        return self\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    \"\"\"\n",
    "    A fully connected neural network with ReLU activations and QAT support.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, layout):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        layers = [nn.Flatten()]\n",
    "        prev_fc_size = input_size\n",
    "        for i, fc_size in enumerate(layout):\n",
    "            if i + 1 < len(layout):\n",
    "                layers += [LinReLU(prev_fc_size, fc_size)]\n",
    "            else:\n",
    "                layers += [nn.Linear(prev_fc_size, 1), nn.Sigmoid()]\n",
    "            prev_fc_size = fc_size\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "            \n",
    "        self.dequant = torch.quantization.DeQuantStub()        \n",
    "        \n",
    "        # self.qconfig = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        \"\"\"\n",
    "        Fuses Linear and ReLU layers in LinReLU modules for QAT\n",
    "        \"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, LinReLU):\n",
    "                torch.quantization.fuse_modules(\n",
    "                    module.layers, \n",
    "                    ['0', '1'],  # Fuse Linear and ReLU\n",
    "                    inplace=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef986af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_matching_prior_mean_square_error(epoch_data, device=None):\n",
    "    \"\"\"\n",
    "    Permutation invariant prior that can be applied over the individual datapoints in the epochs. We first average up\n",
    "    each dataset in the epoch and then calculate pairwise L2 distances between the epoch-data. It is normalized for\n",
    "    number of features and number of epochs.\n",
    "\n",
    "    :param epoch_data: (list of torch.tensor) List of the data-tensors used for each epoch.\n",
    "    :param device: (str) Name of the device on which the tensors are stored. If None is given, the device on which the\n",
    "        first of the epoch data is taken.\n",
    "    :return: prior (torch.tensor) The calculated value of the prior with gradient information.\n",
    "\n",
    "    \"\"\"\n",
    "    n_epochs = len(epoch_data)\n",
    "    n_features = epoch_data[0].size()[-1]\n",
    "    if device is None:\n",
    "        device = epoch_data[0].device\n",
    "    average_local_data = torch.stack([1/data.size()[0] * data.sum(dim=0) for data in epoch_data]).to(device)\n",
    "    prior = torch.tensor([0.], device=device)\n",
    "    for i in range(n_epochs):\n",
    "        prior += 1/(n_epochs**2) * 1/n_features * (average_local_data - average_local_data[i]).pow(2).sum()\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c06d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_local_training_for_attack(client_net, lr, criterion, dataset, labels, original_params,\n",
    "                                       reconstructed_data_per_epoch, local_batch_size, priors=None,\n",
    "                                       epoch_matching_prior=None, softmax_trick=True, gumbel_softmax_trick=False,\n",
    "                                       sigmoid_trick=False, temperature=None, apply_projection_to_features=None,\n",
    "                                       device=None):\n",
    "    \"\"\"\n",
    "    Simulates the local training such that it can be differentiated through with the Pytorch engine.\n",
    "\n",
    "    :param client_net: (MetaMonkey) A MetaMonkey wrapped nn.Module neural network that supports parameter assignment$\n",
    "        directly through assigning and OrderedDict.\n",
    "    :param lr: (float) The learning rate of the local training.\n",
    "    :param criterion: (nn.Module) The loss function of the training.\n",
    "    :param dataset: (datasets.BaseDataset) The dataset with which we work. It contains usually the data necessary for\n",
    "        the calculation of the prior.\n",
    "    :param labels: (torch.tensor) The labels for a whole local epoch, ordered as the batches should be.\n",
    "    :param original_params: (OrderedDict) The original parameter dictionary of the network before training.\n",
    "    :param reconstructed_data_per_epoch: (list of torch.tensor) List of the concatenated batches of data used for\n",
    "        training. This is what we optimize for.\n",
    "    :param local_batch_size: (int) The batch size of the local training.\n",
    "    :param priors: (list of tuple(float, str)) The regularization parameter(s) plus the name(s) of the prior(s) we wish\n",
    "        to use. Default None accounts to no prior.\n",
    "    :param epoch_matching_prior: tuple(float, str) The regularization parameter of the epoch matching prior plus its\n",
    "        name. If None is given (default), then no epoch matching prior will be applied.\n",
    "    :param softmax_trick: (bool) Toggle to apply the softmax trick to the categorical features. Effectively, it serves\n",
    "        as a structural prior on the features.\n",
    "    :param gumbel_softmax_trick: (bool) Toggle to apply the gumbel-softmax trick to the categorical features.\n",
    "    :param sigmoid_trick: (bool) Apply the sigmoid trick to the continuous features to enforce the bounds.\n",
    "    :param apply_projection_to_features: (list) If given, both the softmax trick and the gumbel softmax trick will be\n",
    "        applied only to the set of features given in this list.\n",
    "    :param temperature: (float) Temperature parameter for the softmax in the categorical prior.\n",
    "    :param device: (str) Name of the device on which the tensors are stored.\n",
    "    :return: resulting_two_point_gradient: (list of torch.tensor) Two-point gradient estimate over a local training.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = dataset.device\n",
    "\n",
    "    if apply_projection_to_features is None:\n",
    "        apply_projection_to_features = 'all'\n",
    "\n",
    "    available_priors = {\n",
    "        'categorical_prior': _categorical_prior,\n",
    "        'cont_uniform': _continuous_uniform_prior,\n",
    "        'cont_joint_gmm': _joint_gmm_prior,\n",
    "        'cont_mean_field_gmm': _mean_field_gmm_prior,\n",
    "        'cat_mean_field_JS': _categorical_mean_field_jensen_shannon_prior,\n",
    "        'cat_l2': _categorical_l2_prior,\n",
    "        'theoretical_optimal': _theoretical_optimal_prior,\n",
    "        'theoretical_typicality': _theoretical_typicality_prior,\n",
    "        'theoretical_marginal': _theoretical_marginal_prior,\n",
    "        'theoretical_marginal_typicality': _theoretical_marginal_typicality_prior\n",
    "    }\n",
    "\n",
    "    available_epoch_matching_priors = {\n",
    "        'mean_squared_error': epoch_matching_prior_mean_square_error\n",
    "    }\n",
    "\n",
    "    if priors is not None:\n",
    "        # will raise a key error of we chose a non-implemented prior\n",
    "        prior_params = [prior_params[0] for prior_params in priors]\n",
    "        prior_loss_functions = [available_priors[prior_params[1]] for prior_params in priors]\n",
    "    else:\n",
    "        prior_loss_functions = None\n",
    "        prior_params = None\n",
    "\n",
    "    regularizer = torch.as_tensor([0.0], device=device)\n",
    "\n",
    "    n_data_lines = labels.size()[0]\n",
    "    for local_epoch, reconstructed_data in enumerate(reconstructed_data_per_epoch):\n",
    "\n",
    "        n_batches = int(np.ceil(n_data_lines / local_batch_size))\n",
    "        for b in range(n_batches):\n",
    "            current_batch_X = reconstructed_data[b*local_batch_size:min(n_data_lines, (b+1)*local_batch_size)]\n",
    "            current_batch_y = labels[b*local_batch_size:min(n_data_lines, (b+1)*local_batch_size)].clone().detach()\n",
    "\n",
    "            # apply softmax or gumbel-softmax\n",
    "            if gumbel_softmax_trick:\n",
    "                x_rec = categorical_gumbel_softmax_sampling(current_batch_X, tau=temperature, dataset=dataset)\n",
    "                categoricals_projected = True\n",
    "            elif softmax_trick:\n",
    "                x_rec = categorical_softmax(current_batch_X, tau=temperature, dataset=dataset,\n",
    "                                            apply_to=apply_projection_to_features)\n",
    "                categoricals_projected = True\n",
    "            else:\n",
    "                x_rec = current_batch_X * 1.\n",
    "                categoricals_projected = False\n",
    "\n",
    "            if sigmoid_trick:\n",
    "                x_rec = continuous_sigmoid_bound(x_rec, dataset=dataset, T=temperature)\n",
    "\n",
    "            outputs = client_net(x_rec, client_net.parameters)\n",
    "\n",
    "            #Change by Chirag\n",
    "\n",
    "            current_batch_y=current_batch_y.unsqueeze(1).float()\n",
    "\n",
    "            training_loss = criterion(outputs, current_batch_y)\n",
    "            grad = torch.autograd.grad(training_loss, client_net.parameters.values(), retain_graph=True,\n",
    "                                       create_graph=True, only_inputs=True, allow_unused=True)\n",
    "\n",
    "            client_net.parameters = OrderedDict((name, param - lr * param_grad) for ((name, param), param_grad) in zip(client_net.parameters.items(), grad))\n",
    "\n",
    "            # keep track of a regularizer if needed\n",
    "            if priors is not None:\n",
    "                for prior_param, prior_function in zip(prior_params, prior_loss_functions):\n",
    "                    regularizer += 1/(n_batches*local_epoch) * prior_param * prior_function(x_reconstruct=x_rec,\n",
    "                                                                                            dataset=dataset,\n",
    "                                                                                            softmax_trick=categoricals_projected,\n",
    "                                                                                            labels=current_batch_y,\n",
    "                                                                                            T=temperature)\n",
    "\n",
    "    # if we have an epoch matching prior, we calculate its value, for this, we have to reapply any projections made on\n",
    "    # the data previously\n",
    "    if epoch_matching_prior is not None:\n",
    "        epoch_matching_prior_param = epoch_matching_prior[0]\n",
    "        epoch_matching_prior_function = available_epoch_matching_priors[epoch_matching_prior[1]]\n",
    "\n",
    "        # reapply the projections if any\n",
    "        if softmax_trick or gumbel_softmax_trick:\n",
    "            projected_epoch_data = [categorical_softmax(epoch_data, dataset=dataset, tau=temperature,\n",
    "                                                        apply_to=apply_projection_to_features) for epoch_data in reconstructed_data_per_epoch]\n",
    "        else:\n",
    "            projected_epoch_data = reconstructed_data_per_epoch\n",
    "        # reapply the sigmoid if given\n",
    "        if sigmoid_trick:\n",
    "            projected_bounded_epoch_data = [continuous_sigmoid_bound(pd, dataset=dataset, T=temperature) for pd in projected_epoch_data]\n",
    "        else:\n",
    "            projected_bounded_epoch_data = projected_epoch_data\n",
    "        regularizer += epoch_matching_prior_param * epoch_matching_prior_function(projected_bounded_epoch_data, device=device)\n",
    "\n",
    "    # end of training, time to extract the parameters\n",
    "    resulting_parameters = list(client_net.parameters.values())\n",
    "    resulting_two_point_gradient = [original_param - param for original_param, param in\n",
    "                                    zip(original_params, resulting_parameters)]\n",
    "\n",
    "    return resulting_two_point_gradient, regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf7ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg_attack(original_net, attacked_clients_params, n_local_epochs, local_batch_size, lr,\n",
    "                   dataset, per_client_ground_truth_data, per_client_ground_truth_labels, attack_iterations=1000,\n",
    "                   attack_learning_rate=0.06, reconstruction_loss='cosine_sim', priors=None, epoch_matching_prior=None,\n",
    "                   initialization_mode='uniform', softmax_trick=True, gumbel_softmax_trick=False, temperature_mode=None,\n",
    "                   sigmoid_trick=False, sign_trick=True, apply_projection_to_features=None, device=None):\n",
    "    \"\"\"\n",
    "    FedAVG attack following Dimitrov et al. 2022.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = dataset.device\n",
    "\n",
    "    # attack setups\n",
    "    rec_loss_function = {\n",
    "        'squared_error': _squared_error_loss,\n",
    "        'cosine_sim': _cosine_similarity_loss,\n",
    "        'weighted_combined': _weighted_CS_SE_loss,\n",
    "        'norm_weighted_combined': _gradient_norm_weighted_CS_SE_loss\n",
    "    }\n",
    "\n",
    "    initialization = {\n",
    "        'uniform': _uniform_initialization,\n",
    "        'gaussian': _gaussian_initialization,\n",
    "        'mean': _mean_initialization,\n",
    "        'dataset_sample': _dataset_sample_initialization,\n",
    "        'likelihood_sample': _likelihood_prior_sample_initialization,\n",
    "        'mixed': _mixed_initialization,\n",
    "        'best_sample': _best_sample_initialization\n",
    "    }\n",
    "\n",
    "    temperature_configs = {\n",
    "        'cool': (1000., 0.98),\n",
    "        'constant': (1., 1.),\n",
    "        'heat': (0.1, 1.01)\n",
    "    }\n",
    "\n",
    "    if reconstruction_loss not in list(rec_loss_function.keys()):\n",
    "        raise NotImplementedError(\n",
    "            f'The desired loss function is not implemented, available loss function are: {list(rec_loss_function.keys())}')\n",
    "\n",
    "    final_reconstructions_per_client = []\n",
    "    final_loss_per_client = []\n",
    "\n",
    "    # we will go by attacked client and then completely restart every time\n",
    "    for attacked_client, (attacked_client_params, ground_truth_data, ground_truth_labels) in enumerate(zip(attacked_clients_params, per_client_ground_truth_data, per_client_ground_truth_labels)):\n",
    "        # fix the client network and extract its starting parameters\n",
    "        original_params = [param.detach().clone() for param in original_net.parameters()]\n",
    "        \n",
    "        for original_param, new_param in zip(original_params, attacked_client_params):\n",
    "             print(f\"Original param shape: {original_param.shape}, New param shape: {new_param.shape}\")\n",
    "\n",
    "        true_two_point_gradient = [(original_param - new_param).detach().clone() for original_param, new_param in zip(original_params, attacked_client_params)]\n",
    "\n",
    "        # we reconstruct independently in each epoch and aggregate in the end, as per Dimitrov et al.\n",
    "        # initialize the data\n",
    "        reconstructed_data_per_epoch = [initialization[initialization_mode](ground_truth_data, dataset, device) for _ in range(n_local_epochs)]\n",
    "        for reconstructed_data in reconstructed_data_per_epoch:\n",
    "            reconstructed_data.requires_grad = True\n",
    "\n",
    "        optimizer = torch.optim.Adam(reconstructed_data_per_epoch, lr=attack_learning_rate)\n",
    "\n",
    "        T = temperature_configs[temperature_mode][0]\n",
    "\n",
    "        for it in range(attack_iterations):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            original_net.zero_grad()\n",
    "            client_net = MetaMonkey(copy.deepcopy(original_net))\n",
    "            # criterion = torch.nn.CrossEntropyLoss()\n",
    "            criterion = torch.nn.BCELoss()\n",
    "\n",
    "            resulting_two_point_gradient, regularizer = simulate_local_training_for_attack(\n",
    "                client_net=client_net,\n",
    "                lr=lr,\n",
    "                criterion=criterion,\n",
    "                dataset=dataset,\n",
    "                labels=ground_truth_labels,\n",
    "                original_params=original_params,\n",
    "                reconstructed_data_per_epoch=reconstructed_data_per_epoch,\n",
    "                local_batch_size=local_batch_size,\n",
    "                priors=priors,\n",
    "                epoch_matching_prior=epoch_matching_prior,\n",
    "                softmax_trick=softmax_trick,\n",
    "                gumbel_softmax_trick=gumbel_softmax_trick,\n",
    "                sigmoid_trick=sigmoid_trick,\n",
    "                apply_projection_to_features=apply_projection_to_features,\n",
    "                temperature=T\n",
    "            )\n",
    "\n",
    "            # calculate the final objective\n",
    "            loss = rec_loss_function[reconstruction_loss](resulting_two_point_gradient, true_two_point_gradient, device)\n",
    "            loss += regularizer\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            if sign_trick:\n",
    "                for reconstructed_data in reconstructed_data_per_epoch:\n",
    "                    reconstructed_data.grad.sign_()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # adjust the temperature\n",
    "            T *= temperature_configs[temperature_mode][1]\n",
    "\n",
    "        # if we used the sigmoid trick, we reapply it\n",
    "        if sigmoid_trick:\n",
    "            sigmoid_reconstruction = [continuous_sigmoid_bound(rd, dataset=dataset, T=T) for rd in reconstructed_data_per_epoch]\n",
    "            reconstructed_data_per_epoch = sigmoid_reconstruction\n",
    "\n",
    "        # after the optimization has finished for the given client, we project and match the data\n",
    "        epoch_pooling = 'soft_avg+softmax' if softmax_trick or gumbel_softmax_trick else 'soft_avg'\n",
    "        final_reconstruction = pooled_ensemble([reconstructed_data.clone().detach() for reconstructed_data in reconstructed_data_per_epoch],\n",
    "                                               reconstructed_data_per_epoch[0].clone().detach(), dataset,\n",
    "                                               pooling=epoch_pooling)\n",
    "        final_reconstructions_per_client.append(final_reconstruction)\n",
    "\n",
    "        # with the aggregated datapoint, we can finally run it again through the process to record its loss\n",
    "        final_reconstruction_projected = dataset.project_batch(final_reconstruction, standardized=dataset.standardized)\n",
    "        client_net = MetaMonkey(copy.deepcopy(original_net))\n",
    "\n",
    "        # criterion = torch.nn.CrossEntropyLoss()\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        final_resulting_two_point_gradient, _ = simulate_local_training_for_attack(\n",
    "                client_net=client_net,\n",
    "                lr=lr,\n",
    "                criterion=criterion,\n",
    "                dataset=dataset,\n",
    "                labels=ground_truth_labels,\n",
    "                original_params=original_params,\n",
    "                reconstructed_data_per_epoch=[final_reconstruction_projected for _ in range(n_local_epochs)],\n",
    "                local_batch_size=local_batch_size,\n",
    "                priors=None,\n",
    "                softmax_trick=softmax_trick,\n",
    "                gumbel_softmax_trick=gumbel_softmax_trick,\n",
    "                apply_projection_to_features=apply_projection_to_features,\n",
    "                temperature=T\n",
    "        )\n",
    "        final_loss = rec_loss_function[reconstruction_loss](final_resulting_two_point_gradient, true_two_point_gradient, device)\n",
    "        final_loss_per_client.append(final_loss.detach().item())\n",
    "\n",
    "    return final_reconstructions_per_client, final_loss_per_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cea69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a39653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_attack_fed_avg(net, n_clients, n_global_epochs, n_local_epochs, local_batch_size, lr, dataset, shuffle=False,\n",
    "#                              attacked_clients=None, attack_iterations=1000, reconstruction_loss='cosine_sim', priors=None,\n",
    "#                              epoch_matching_prior=None, post_selection=1, attack_learning_rate=0.06, return_all=False,\n",
    "#                              pooling=None, perfect_pooling=False, initialization_mode='uniform', softmax_trick=True,\n",
    "#                              gumbel_softmax_trick=False, sigmoid_trick=False, temperature_mode='constant',\n",
    "#                              sign_trick=True, fish_for_features=None, device=None, verbose=False, max_n_cpus=50, first_cpu=0,\n",
    "#                              max_client_dataset_size=None, parallelized=False, metadata_path='metadata', state_name=\"AL\"):\n",
    "\n",
    "#     if device is None:\n",
    "#         device = dataset.device\n",
    "\n",
    "#     if attacked_clients is None:\n",
    "#         attacked_clients = []\n",
    "#     elif attacked_clients == 'all':\n",
    "#         attacked_clients = list(np.arange(n_clients))\n",
    "\n",
    "#     if max_client_dataset_size is None:\n",
    "#         max_client_dataset_size = len(dataset)\n",
    "\n",
    "#     per_global_epoch_per_client_reconstructions = []\n",
    "#     per_global_epoch_per_client_ground_truth = []\n",
    "#     training_data = np.zeros((n_global_epochs, 2))\n",
    "    \n",
    "\n",
    "#     # Split data into client datasets\n",
    "#     if shuffle:\n",
    "#         dataset.shuffle()\n",
    "\n",
    "#     Xtrain, ytrain = dataset.get_Xtrain(), dataset.get_ytrain()\n",
    "#     split_size = min(max_client_dataset_size, int(np.ceil(Xtrain.size()[0] / n_clients)))\n",
    "#     Xtrain_splits = [Xtrain[i*split_size:min(int(Xtrain.size()[0]), (i+1)*split_size)].clone().detach() for i in range(n_clients)]\n",
    "#     ytrain_splits = [ytrain[i*split_size:min(int(Xtrain.size()[0]), (i+1)*split_size)].clone().detach() for i in range(n_clients)]\n",
    "\n",
    "#     # Loss function\n",
    "#     criterion = torch.nn.BCELoss()\n",
    "#     timer = Timer(n_global_epochs)\n",
    "#     # Load pre-trained model\n",
    "#     pre_trained_model_path = \"50_clients_data/clients_trained_model/pre_trained_model.pth\"\n",
    "#     state_dict = torch.load(pre_trained_model_path)\n",
    "#     weights_dict = {k: v for k, v in state_dict.items() if 'weight' in k}\n",
    "#     net.load_state_dict(weights_dict, strict=False)\n",
    "#     print(\"Pre-trained model loaded.\")\n",
    "\n",
    "    \n",
    "#     def prepare_qat_model(model, backend='qnnpack'):\n",
    "#         \"\"\"\n",
    "#         Prepare model for Quantization Aware Training\n",
    "#         \"\"\"\n",
    "#         model.qconfig = torch.quantization.get_default_qat_qconfig(backend)\n",
    "#         torch.backends.quantized.engine = backend\n",
    "#         model.fuse_model()\n",
    "#         torch.quantization.prepare_qat(model, inplace=True)\n",
    "#         return model\n",
    "\n",
    "#     # Training loop\n",
    "#     for global_epoch in range(n_global_epochs):\n",
    "#         acc, bac = get_acc_and_bac(net, dataset.get_Xtest(), dataset.get_ytest())\n",
    "#         if verbose:\n",
    "#             print(f'Global Epochs: {global_epoch + 1}/{n_global_epochs}    Acc: {acc * 100:.2f}%    BAcc: {bac * 100:.2f}%')\n",
    "\n",
    "#         training_data[global_epoch] = acc, bac\n",
    "\n",
    "#         # Create client networks\n",
    "#         # client_nets = [copy.deepcopy(net) for _ in range(n_clients)]\n",
    "#         # client_nets = [prepare_qat_model(client_net) for client_net in client_nets]\n",
    "\n",
    "\n",
    "#         # After creating client networks\n",
    "#         client_nets = [copy.deepcopy(net) for _ in range(n_clients)]\n",
    "#         client_nets = [prepare_qat_model(client_net) for client_net in client_nets]\n",
    "\n",
    "#         for client, (client_X, client_y, client_net) in enumerate(zip(Xtrain_splits, ytrain_splits, client_nets)):\n",
    "#             client_net.train()  # Set to training mode for QAT\n",
    "#             n_batches = int(np.ceil(client_X.size()[0] / local_batch_size))\n",
    "\n",
    "#             print(f\"Training client {client + 1}/{n_clients}\")\n",
    "#             print(\"QAT training\")\n",
    "#             print(\"n_batches is\", n_batches)\n",
    "#             print(\"local_epoch is\", n_local_epochs)\n",
    "\n",
    "#             # Training loop remains the same\n",
    "#             for local_epoch in range(n_local_epochs):\n",
    "#                 for b in range(n_batches):\n",
    "#                     current_batch_X = client_X[b * local_batch_size:min(int(client_X.size()[0]), (b+1)*local_batch_size)].clone().detach()\n",
    "#                     current_batch_y = client_y[b * local_batch_size:min(int(client_X.size()[0]), (b+1)*local_batch_size)].clone().detach()\n",
    "#                     outputs = client_net(current_batch_X)\n",
    "\n",
    "#                     current_batch_y = current_batch_y.unsqueeze(1).float()\n",
    "#                     loss = criterion(outputs, current_batch_y)\n",
    "#                     grad = torch.autograd.grad(loss, client_net.parameters(), retain_graph=True)\n",
    "\n",
    "#                     with torch.no_grad():\n",
    "#                         for param, param_grad in zip(client_net.parameters(), grad):\n",
    "#                             param -= lr * param_grad\n",
    "\n",
    "#             # Evaluation phase\n",
    "#             client_net.eval()\n",
    "            \n",
    "#             # First evaluate QAT model\n",
    "#             val_running_loss = 0.0\n",
    "#             val_correct = 0\n",
    "#             val_total = 0\n",
    "\n",
    "#             inputs, labels = dataset.get_Xtest(), dataset.get_ytest()\n",
    "#             labels = labels.unsqueeze(1).float()\n",
    "#             val_n_batches = int(np.ceil(inputs.size()[0] / local_batch_size))\n",
    "            \n",
    "#             with torch.no_grad():\n",
    "#                 for b in range(val_n_batches):\n",
    "#                     val_batch_X = inputs[b * local_batch_size:min(int(inputs.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "#                     val_batch_y = labels[b * local_batch_size:min(int(labels.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "\n",
    "#                     outputs = client_net(val_batch_X)\n",
    "#                     val_loss = criterion(outputs, val_batch_y)\n",
    "#                     val_running_loss += val_loss.item()\n",
    "\n",
    "#                     predicted_classes = (outputs > 0.5).float()\n",
    "#                     val_correct += (predicted_classes == val_batch_y).sum().item()\n",
    "#                     val_total += val_batch_y.size(0)\n",
    "\n",
    "#             val_epoch_loss = val_running_loss / len(inputs)\n",
    "#             val_accuracy = val_correct / val_total\n",
    "#             print(f\"QAT Model - Validation Accuracy: {val_accuracy:.4f}, Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "#             # Save QAT model\n",
    "#             qat_model_path = f\"50_clients_data/clients_trained_model/qat_{state_name}.pth\"\n",
    "#             torch.save(client_net.state_dict(), qat_model_path)\n",
    "#             print(f\"QAT model is saved to {qat_model_path}\")\n",
    "#             print(\"QAT Model Size:\", os.path.getsize(qat_model_path) / 1024, \"KB\")\n",
    "\n",
    "#             quantized_net = torch.quantization.convert(client_net.eval(), inplace=False)\n",
    "            \n",
    "#             # # Evaluate quantized model\n",
    "#             # val_running_loss = 0.0\n",
    "#             # val_correct = 0\n",
    "#             # val_total = 0\n",
    "\n",
    "#             # with torch.no_grad():\n",
    "#             #     for b in range(val_n_batches):\n",
    "#             #         val_batch_X = inputs[b * local_batch_size:min(int(inputs.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "#             #         val_batch_y = labels[b * local_batch_size:min(int(labels.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "\n",
    "#             #         outputs = quantized_net(val_batch_X)\n",
    "#             #         val_loss = criterion(outputs, val_batch_y)\n",
    "#             #         val_running_loss += val_loss.item()\n",
    "\n",
    "#             #         predicted_classes = (outputs > 0.5).float()\n",
    "#             #         val_correct += (predicted_classes == val_batch_y).sum().item()\n",
    "#             #         val_total += val_batch_y.size(0)\n",
    "\n",
    "#             # val_epoch_loss = val_running_loss / len(inputs)\n",
    "#             # val_accuracy = val_correct / val_total\n",
    "#             # print(f\"Quantized Model - Validation Accuracy: {val_accuracy:.4f}, Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "#             # # Save quantized model\n",
    "#             model_path = f\"50_clients_data/clients_trained_model/quantized_{state_name}.pth\"\n",
    "#             torch.save(quantized_net.state_dict(), model_path)\n",
    "#             print(f\"Quantized model saved to {model_path}\")\n",
    "#             print(\"Quantized Model Size:\", os.path.getsize(model_path) / 1024, \"KB\")\n",
    "\n",
    "\n",
    "#         # quantization_flag= True\n",
    "#         # if quantization_flag is True:\n",
    "#         #     print(\"Attack on quantized_net\")\n",
    "#         #     # clients_params = [[param.clone().detach() for param in quantized_net.parameters()] for quantized_net in client_nets]\n",
    "#         #     clients_params = [[param.clone().detach() for param in quantized_net.parameters()] for client_net in client_nets]\n",
    "#         # else:\n",
    "#         #     clients_params = [[param.clone().detach() for param in client_net.parameters()] for client_net in client_nets]\n",
    "\n",
    "#         clients_params = [[param.clone().detach() for param in client_net.parameters()] for client_net in client_nets]\n",
    "\n",
    "#         # quantization_flag = True\n",
    "#         # if quantization_flag is True:\n",
    "#         #     print(\"Attack on quantized_net\")                                    \n",
    "#         #     quantized_nets = []\n",
    "#         #     for client_net in client_nets:\n",
    "#         #         client_net.eval()\n",
    "#         #         quantized_net = torch.quantization.convert(client_net, inplace=False)\n",
    "#         #         quantized_nets.append(quantized_net)\n",
    "#         #     clients_params = [[param.clone().detach() for param in qnet.parameters()] for qnet in quantized_nets]\n",
    "#         # else:\n",
    "#         #     clients_params = [[param.clone().detach() for param in client_net.parameters()] for client_net in client_nets]\n",
    "\n",
    "#         attack_bool= True\n",
    "#         if attack_bool is False:\n",
    "#             print(\"---------------------------------------\")\n",
    "#             print(\"-----Attack Is NOT Being Applied-------\")\n",
    "#             print(\"---------------------------------------\")\n",
    "#             break\n",
    "#         else:\n",
    "#             # -------------- ATTACK -------------- #\n",
    "#             per_client_all_reconstructions = [[] for _ in range(len(attacked_clients))]\n",
    "#             per_client_best_reconstructions = [None for _ in range(len(attacked_clients))]\n",
    "#             per_client_best_scores = [None for _ in range(len(attacked_clients))]\n",
    "#             per_client_ground_truth_data = [Xtrain_splits[attacked_client].detach().clone() for attacked_client in attacked_clients]\n",
    "#             per_client_ground_truth_labels = [ytrain_splits[attacked_client].detach().clone() for attacked_client in attacked_clients]\n",
    "#             attacked_clients_params = [[param.clone().detach() for param in clients_params[attacked_client]] for attacked_client in attacked_clients]\n",
    "#             print(attacked_clients_params,\"attacked_clients_params\")\n",
    "#             for _ in range(post_selection):\n",
    "\n",
    "#                 if parallelized:\n",
    "#                     print(\"parallelized\")\n",
    "#                     per_client_candidate_reconstructions, per_client_final_losses = fed_avg_attack_parallelized_over_clients(\n",
    "#                         original_net=copy.deepcopy(net),\n",
    "#                         attacked_clients_params=attacked_clients_params,\n",
    "#                         attack_iterations=attack_iterations,\n",
    "#                         attack_learning_rate=attack_learning_rate,\n",
    "#                         n_local_epochs=n_local_epochs,\n",
    "#                         local_batch_size=local_batch_size,\n",
    "#                         lr=lr,\n",
    "#                         dataset=dataset,\n",
    "#                         per_client_ground_truth_data=per_client_ground_truth_data,\n",
    "#                         per_client_ground_truth_labels=per_client_ground_truth_labels,\n",
    "#                         reconstruction_loss=reconstruction_loss,\n",
    "#                         priors=priors,\n",
    "#                         epoch_matching_prior=epoch_matching_prior,\n",
    "#                         initialization_mode=initialization_mode,\n",
    "#                         softmax_trick=softmax_trick,\n",
    "#                         gumbel_softmax_trick=gumbel_softmax_trick,\n",
    "#                         sigmoid_trick=sigmoid_trick,\n",
    "#                         temperature_mode=temperature_mode,\n",
    "#                         sign_trick=sign_trick,\n",
    "#                         apply_projection_to_features=fish_for_features,\n",
    "#                         max_n_cpus=max_n_cpus,\n",
    "#                         first_cpu=first_cpu,\n",
    "#                         device=device,\n",
    "#                         metadata_path=metadata_path\n",
    "#                     )\n",
    "\n",
    "#                 else:\n",
    "#                     print(\"parallelized--OFF \")\n",
    "#                     per_client_candidate_reconstructions, per_client_final_losses = fed_avg_attack(\n",
    "#                         original_net=copy.deepcopy(net),\n",
    "#                         attacked_clients_params=attacked_clients_params,\n",
    "#                         attack_iterations=attack_iterations,\n",
    "#                         attack_learning_rate=attack_learning_rate,\n",
    "#                         n_local_epochs=n_local_epochs,\n",
    "#                         local_batch_size=local_batch_size,\n",
    "#                         lr=lr,\n",
    "#                         dataset=dataset,\n",
    "#                         per_client_ground_truth_data=per_client_ground_truth_data,\n",
    "#                         per_client_ground_truth_labels=per_client_ground_truth_labels,\n",
    "#                         reconstruction_loss=reconstruction_loss,\n",
    "#                         priors=priors,\n",
    "#                         epoch_matching_prior=epoch_matching_prior,\n",
    "#                         initialization_mode=initialization_mode,\n",
    "#                         softmax_trick=softmax_trick,\n",
    "#                         gumbel_softmax_trick=gumbel_softmax_trick,\n",
    "#                         sigmoid_trick=sigmoid_trick,\n",
    "#                         temperature_mode=temperature_mode,\n",
    "#                         sign_trick=sign_trick,\n",
    "#                         apply_projection_to_features=fish_for_features,\n",
    "#                         device=device\n",
    "#                     )\n",
    "\n",
    "#                 # enter the results in the collectors\n",
    "#                 for client_idx in range(len(attacked_clients)):\n",
    "#                     per_client_all_reconstructions[client_idx].append(per_client_candidate_reconstructions[client_idx].detach().clone())\n",
    "#                     if (per_client_best_scores[client_idx] is None) or (per_client_best_scores[client_idx] > per_client_final_losses[client_idx]):\n",
    "#                         per_client_best_scores[client_idx] = per_client_final_losses[client_idx]\n",
    "#                         per_client_best_reconstructions[client_idx] = per_client_candidate_reconstructions[client_idx].detach().clone()\n",
    "\n",
    "#             if return_all:\n",
    "#                 per_global_epoch_per_client_reconstructions.append(per_client_all_reconstructions)\n",
    "#             elif pooling is not None:\n",
    "#                 if perfect_pooling:\n",
    "#                     per_client_pooled = [pooled_ensemble(all_reconstructions, ground_truth_data, dataset, pooling=pooling)\n",
    "#                                         for all_reconstructions, ground_truth_data in zip(per_client_all_reconstructions, per_client_ground_truth_data)]\n",
    "#                 else:\n",
    "#                     per_client_pooled = [pooled_ensemble(all_reconstructions, best_reconstruction, dataset, pooling=pooling)\n",
    "#                                         for all_reconstructions, best_reconstruction in zip(per_client_all_reconstructions, per_client_best_reconstructions)]\n",
    "#                 per_global_epoch_per_client_reconstructions.append(per_client_pooled)\n",
    "#             else:\n",
    "#                 per_global_epoch_per_client_reconstructions.append(per_client_best_reconstructions)\n",
    "#             per_global_epoch_per_client_ground_truth.append(per_client_ground_truth_data)\n",
    "#             # -------------- ATTACK END -------------- #\n",
    "\n",
    "#         # Continue the training\n",
    "#         # transpose the list\n",
    "#         transposed_clients_params = [[] for _ in range(len(clients_params[0]))]\n",
    "#         for client_params in clients_params:\n",
    "#             for i, param in enumerate(client_params):\n",
    "#                 transposed_clients_params[i].append(param.clone().detach())\n",
    "\n",
    "#         # aggregate the params using mean aggregation\n",
    "#         aggregated_params = [torch.mean(torch.stack(params_over_clients), dim=0) for params_over_clients in transposed_clients_params]\n",
    "\n",
    "#         # write the new parameters into the main network\n",
    "#         with torch.no_grad():\n",
    "#             for param, agg_param in zip(net.parameters(), aggregated_params):\n",
    "#                 param.copy_(agg_param)\n",
    "        \n",
    "#         # timer.end()\n",
    "#     # timer.duration()\n",
    "\n",
    "#     # random_baseline = calculate_random_baseline(dataset=dataset, recover_batch_sizes=reconstruction_batch_sizes,\n",
    "#     #                                                     tolerance_map=tolerance_map, n_samples=n_samples, mode=mode,\n",
    "#     #                                                     device=args.device)\n",
    "\n",
    "#     return net, training_data, per_global_epoch_per_client_reconstructions, per_global_epoch_per_client_ground_truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb6c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d414c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_attack_fed_avg(net, n_clients, n_global_epochs, n_local_epochs, local_batch_size, lr, dataset, shuffle=False,\n",
    "                             attacked_clients=None, attack_iterations=1000, reconstruction_loss='cosine_sim', priors=None,\n",
    "                             epoch_matching_prior=None, post_selection=1, attack_learning_rate=0.06, return_all=False,\n",
    "                             pooling=None, perfect_pooling=False, initialization_mode='uniform', softmax_trick=True,\n",
    "                             gumbel_softmax_trick=False, sigmoid_trick=False, temperature_mode='constant',\n",
    "                             sign_trick=True, fish_for_features=None, device=None, verbose=False, max_n_cpus=50, first_cpu=0,\n",
    "                             max_client_dataset_size=None, parallelized=False, metadata_path='metadata', state_name=\"AL\"):\n",
    "\n",
    "    if device is None:\n",
    "        device = dataset.device\n",
    "\n",
    "    if attacked_clients is None:\n",
    "        attacked_clients = []\n",
    "    elif attacked_clients == 'all':\n",
    "        attacked_clients = list(np.arange(n_clients))\n",
    "\n",
    "    if max_client_dataset_size is None:\n",
    "        max_client_dataset_size = len(dataset)\n",
    "\n",
    "    per_global_epoch_per_client_reconstructions = []\n",
    "    per_global_epoch_per_client_ground_truth = []\n",
    "    training_data = np.zeros((n_global_epochs, 2))\n",
    "    \n",
    "\n",
    "    # Split data into client datasets\n",
    "    if shuffle:\n",
    "        dataset.shuffle()\n",
    "\n",
    "    Xtrain, ytrain = dataset.get_Xtrain(), dataset.get_ytrain()\n",
    "    split_size = min(max_client_dataset_size, int(np.ceil(Xtrain.size()[0] / n_clients)))\n",
    "    Xtrain_splits = [Xtrain[i*split_size:min(int(Xtrain.size()[0]), (i+1)*split_size)].clone().detach() for i in range(n_clients)]\n",
    "    ytrain_splits = [ytrain[i*split_size:min(int(Xtrain.size()[0]), (i+1)*split_size)].clone().detach() for i in range(n_clients)]\n",
    "\n",
    "    # Loss function\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    timer = Timer(n_global_epochs)\n",
    "    # Load pre-trained model\n",
    "    pre_trained_model_path = \"50_clients_data/clients_trained_model/pre_trained_model.pth\"\n",
    "    state_dict = torch.load(pre_trained_model_path)\n",
    "    weights_dict = {k: v for k, v in state_dict.items() if 'weight' in k}\n",
    "    net.load_state_dict(weights_dict, strict=False)\n",
    "    print(\"Pre-trained model loaded.\")\n",
    "\n",
    "\n",
    "    def prepare_qat_model(model, backend='qnnpack'):\n",
    "        \"\"\"\n",
    "        Prepare model for Quantization Aware Training\n",
    "        \"\"\"\n",
    "        model.qconfig = torch.quantization.get_default_qat_qconfig(backend)\n",
    "        torch.backends.quantized.engine = backend\n",
    "        model.fuse_model()\n",
    "        torch.quantization.prepare_qat(model, inplace=True)\n",
    "        return model\n",
    "\n",
    "    def prepare_qat_model_aggresive(model, backend='qnnpack'):\n",
    "        \"\"\"\n",
    "        Prepare model for Quantization Aware Training with aggressive quantization.\n",
    "        \"\"\"\n",
    "        # Aggressive quantization config\n",
    "        model.qconfig = torch.quantization.QConfig(\n",
    "            activation=torch.quantization.FakeQuantize.with_args(observer=torch.quantization.MinMaxObserver, dtype=torch.quint8,\n",
    "                                                                  qscheme=torch.per_tensor_symmetric),\n",
    "            weight=torch.quantization.default_per_channel_weight_fake_quant\n",
    "        )\n",
    "        torch.backends.quantized.engine = backend\n",
    "        model.fuse_model()\n",
    "        torch.quantization.prepare_qat(model, inplace=True)\n",
    "        return model\n",
    "    \n",
    "    def quantize_model_post_train(model, calibration_data, backend='qnnpack'):\n",
    "        model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "        torch.backends.quantized.engine = backend\n",
    "        # model.fuse_model()\n",
    "    \n",
    "        # Prepare model (add observers)\n",
    "        quantized_model = torch.quantization.prepare(model, inplace=False)\n",
    "    \n",
    "        # Calibration step\n",
    "        with torch.no_grad():\n",
    "            for batch_X in calibration_data:\n",
    "                quantized_model(batch_X)\n",
    "    \n",
    "        # Convert to quantized model\n",
    "        quantized_model = torch.quantization.convert(quantized_model, inplace=False)\n",
    "        return quantized_model\n",
    "\n",
    "    # Training loop\n",
    "    for global_epoch in range(n_global_epochs):\n",
    "        acc, bac = get_acc_and_bac(net, dataset.get_Xtest(), dataset.get_ytest())\n",
    "        if verbose:\n",
    "            print(f'Global Epochs: {global_epoch + 1}/{n_global_epochs}    Acc: {acc * 100:.2f}%    BAcc: {bac * 100:.2f}%')\n",
    "\n",
    "        training_data[global_epoch] = acc, bac\n",
    "\n",
    "        # Create client networks\n",
    "\n",
    "        client_nets = [copy.deepcopy(net) for _ in range(n_clients)]\n",
    "        client_nets = [prepare_qat_model(client_net) for client_net in client_nets]\n",
    "    \n",
    "\n",
    "        for client, (client_X, client_y, client_net) in enumerate(zip(Xtrain_splits, ytrain_splits, client_nets)):\n",
    "            client_net.train()  # Set to training mode for QAT\n",
    "            n_batches = int(np.ceil(client_X.size()[0] / local_batch_size))\n",
    "\n",
    "            print(f\"Training client {client + 1}/{n_clients}\")\n",
    "            print(\"QAT training\")\n",
    "            print(\"n_batches is\", n_batches)\n",
    "            print(\"local_epoch is\", n_local_epochs)\n",
    "\n",
    "            # Training loop remains the same\n",
    "            for local_epoch in range(n_local_epochs):\n",
    "                for b in range(n_batches):\n",
    "                    current_batch_X = client_X[b * local_batch_size:min(int(client_X.size()[0]), (b+1)*local_batch_size)].clone().detach()\n",
    "                    current_batch_y = client_y[b * local_batch_size:min(int(client_X.size()[0]), (b+1)*local_batch_size)].clone().detach()\n",
    "                    outputs = client_net(current_batch_X)\n",
    "\n",
    "                    current_batch_y = current_batch_y.unsqueeze(1).float()\n",
    "                    loss = criterion(outputs, current_batch_y)\n",
    "                    grad = torch.autograd.grad(loss, client_net.parameters(), retain_graph=True)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        for param, param_grad in zip(client_net.parameters(), grad):\n",
    "                            param -= lr * param_grad\n",
    "\n",
    "            # Evaluation phase\n",
    "            client_net.eval()\n",
    "\n",
    "            inputs, labels = dataset.get_Xtest(), dataset.get_ytest()\n",
    "            labels = labels.unsqueeze(1).float()\n",
    "            val_n_batches = int(np.ceil(inputs.size()[0] / local_batch_size))\n",
    "            \n",
    "            # Save QAT model\n",
    "            qat_model_path = f\"50_clients_data/clients_trained_model/qat_{state_name}.pth\"\n",
    "            torch.save(client_net.state_dict(), qat_model_path)\n",
    "\n",
    "            print(f\"QAT model is saved to {qat_model_path}\")\n",
    "            print(\"QAT Model Size:\", os.path.getsize(qat_model_path) / 1024, \"KB\")\n",
    "\n",
    "\n",
    "            quantized_net = torch.quantization.convert(client_net.eval(), inplace=False)\n",
    "\n",
    "            # # Evaluate quantized model\n",
    "            val_running_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            quantized_net.eval()\n",
    "            print(\"quantized_net is being used for testing\")\n",
    "            with torch.no_grad():\n",
    "                for b in range(val_n_batches):\n",
    "                    val_batch_X = inputs[b * local_batch_size:min(int(inputs.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "                    val_batch_y = labels[b * local_batch_size:min(int(labels.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "\n",
    "                    outputs = quantized_net(val_batch_X)\n",
    "                    val_loss = criterion(outputs, val_batch_y)\n",
    "                    val_running_loss += val_loss.item()\n",
    "\n",
    "                    predicted_classes = (outputs > 0.5).float()\n",
    "                    val_correct += (predicted_classes == val_batch_y).sum().item()\n",
    "                    val_total += val_batch_y.size(0)\n",
    "\n",
    "            val_epoch_loss = val_running_loss / len(inputs)\n",
    "            val_accuracy = val_correct / val_total\n",
    "            print(f\"Quantized Model - Validation Accuracy: {val_accuracy:.4f}, Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "            # # Save quantized model\n",
    "            model_path = f\"50_clients_data/clients_trained_model/quantized_{state_name}.pth\"\n",
    "            torch.save(quantized_net.state_dict(), model_path)\n",
    "            print(f\"Quantized model saved to {model_path}\")\n",
    "            print(\"Quantized Model Size:\", os.path.getsize(model_path) / 1024, \"KB\")\n",
    "\n",
    "\n",
    "        # print(list(quantized_net.state_dict().values()),\"clients_params--After\")\n",
    "        # clients_params=[list(quantized_net.state_dict().values())]\n",
    "\n",
    "       #----------------- Need to Check this ------------------------#\n",
    "        processed_params = []\n",
    "\n",
    "        # just to check the shape\n",
    "        original_params = [param.clone().detach() for param in net.parameters()]\n",
    "\n",
    "        for original_param in original_params:\n",
    "            matched = False \n",
    "            for name, module in quantized_net.named_modules():\n",
    "                if hasattr(module, 'weight') and module.weight is not None:\n",
    "                    weight = module.weight\n",
    "                    \n",
    "                    weight_tensor = weight() if callable(weight) else weight\n",
    "                    if isinstance(weight_tensor, torch.Tensor):\n",
    "                        weight_tensor = weight_tensor.dequantize().detach() if weight_tensor.is_quantized else weight_tensor.detach()\n",
    "                    \n",
    "                        if weight_tensor.shape == original_param.shape:\n",
    "                            processed_params.append(weight_tensor)\n",
    "                            matched = True\n",
    "                            break \n",
    "\n",
    "                if hasattr(module, 'bias') and module.bias is not None:\n",
    "                    bias = module.bias\n",
    "                    \n",
    "                    bias_tensor = bias() if callable(bias) else bias\n",
    "                    if isinstance(bias_tensor, torch.Tensor):\n",
    "                        bias_tensor = bias_tensor.detach()\n",
    "                       \n",
    "                        if bias_tensor.shape == original_param.shape:\n",
    "                            processed_params.append(bias_tensor)\n",
    "                            matched = True\n",
    "                            break \n",
    "\n",
    "            if not matched:\n",
    "                print(f\"Warning: No matching parameter found for shape {original_param.shape}\")\n",
    "\n",
    "        # processed_params = []\n",
    "\n",
    "        # # Clone and detach original parameters for comparison\n",
    "        # original_params = [param.clone().detach() for param in net.parameters()]\n",
    "\n",
    "        # for original_param in original_params:\n",
    "        #     matched = False  # Flag to ensure only one match per original_param\n",
    "        #     for name, module in quantized_net.named_modules():\n",
    "        #         if hasattr(module, 'weight') and module.weight is not None:\n",
    "        #             weight = module.weight\n",
    "        #             # Handle packed weights\n",
    "        #             weight_tensor = weight() if callable(weight) else weight\n",
    "        #             if isinstance(weight_tensor, torch.Tensor) and weight_tensor.is_quantized:  # Ensure it's quantized\n",
    "        #                 weight_tensor = weight_tensor.dequantize().detach()\n",
    "\n",
    "        #                 # Check if the shape matches the original parameter\n",
    "        #                 if weight_tensor.shape == original_param.shape:\n",
    "        #                     processed_params.append(weight_tensor)\n",
    "        #                     matched = True\n",
    "        #                     break  # Move to the next original parameter\n",
    "\n",
    "        #         if hasattr(module, 'bias') and module.bias is not None:\n",
    "        #             bias = module.bias\n",
    "        #             # Handle packed biases\n",
    "        #             bias_tensor = bias() if callable(bias) else bias\n",
    "        #             if isinstance(bias_tensor, torch.Tensor):  # Bias is typically not quantized\n",
    "        #                 bias_tensor = bias_tensor.detach()\n",
    "\n",
    "        #                 # Check if the shape matches the original parameter\n",
    "        #                 if bias_tensor.shape == original_param.shape:\n",
    "        #                     processed_params.append(bias_tensor)\n",
    "        #                     matched = True\n",
    "        #                     break  # Move to the next original parameter\n",
    "\n",
    "        #     if not matched:\n",
    "        #         print(f\"Warning: No matching quantized parameter found for shape {original_param.shape}\")\n",
    "\n",
    "        clients_params = processed_params\n",
    "\n",
    "        attacked_clients_params=[clients_params]\n",
    "\n",
    "        # THis will not work in Quantization.\n",
    "        # clients_params = [[param.clone().detach() for param in client_net.parameters()] for client_net in client_nets]\n",
    "        # print(clients_params,\"clients_params After\")\n",
    "        \n",
    "        attack_bool= True\n",
    "        if attack_bool is False:\n",
    "            print(\"---------------------------------------\")\n",
    "            print(\"-----Attack Is NOT Being Applied-------\")\n",
    "            print(\"---------------------------------------\")\n",
    "            break\n",
    "        else:\n",
    "            # -------------- ATTACK -------------- #\n",
    "            per_client_all_reconstructions = [[] for _ in range(len(attacked_clients))]\n",
    "            per_client_best_reconstructions = [None for _ in range(len(attacked_clients))]\n",
    "            per_client_best_scores = [None for _ in range(len(attacked_clients))]\n",
    "            per_client_ground_truth_data = [Xtrain_splits[attacked_client].detach().clone() for attacked_client in attacked_clients]\n",
    "            per_client_ground_truth_labels = [ytrain_splits[attacked_client].detach().clone() for attacked_client in attacked_clients]\n",
    "            # attacked_clients_params = [[param.clone().detach() for param in clients_params[attacked_client]] for attacked_client in attacked_clients]\n",
    "\n",
    "            # attacked_clients_params=[clients_params]\n",
    "            # print(attacked_clients_params,\"attacked_clients_params\")\n",
    "            \n",
    "            for _ in range(post_selection):\n",
    "\n",
    "                if parallelized:\n",
    "                    print(\"parallelized\")\n",
    "                    per_client_candidate_reconstructions, per_client_final_losses = fed_avg_attack_parallelized_over_clients(\n",
    "                        original_net=copy.deepcopy(net),\n",
    "                        attacked_clients_params=attacked_clients_params,\n",
    "                        attack_iterations=attack_iterations,\n",
    "                        attack_learning_rate=attack_learning_rate,\n",
    "                        n_local_epochs=n_local_epochs,\n",
    "                        local_batch_size=local_batch_size,\n",
    "                        lr=lr,\n",
    "                        dataset=dataset,\n",
    "                        per_client_ground_truth_data=per_client_ground_truth_data,\n",
    "                        per_client_ground_truth_labels=per_client_ground_truth_labels,\n",
    "                        reconstruction_loss=reconstruction_loss,\n",
    "                        priors=priors,\n",
    "                        epoch_matching_prior=epoch_matching_prior,\n",
    "                        initialization_mode=initialization_mode,\n",
    "                        softmax_trick=softmax_trick,\n",
    "                        gumbel_softmax_trick=gumbel_softmax_trick,\n",
    "                        sigmoid_trick=sigmoid_trick,\n",
    "                        temperature_mode=temperature_mode,\n",
    "                        sign_trick=sign_trick,\n",
    "                        apply_projection_to_features=fish_for_features,\n",
    "                        max_n_cpus=max_n_cpus,\n",
    "                        first_cpu=first_cpu,\n",
    "                        device=device,\n",
    "                        metadata_path=metadata_path\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(\"parallelized--OFF \")\n",
    "                    per_client_candidate_reconstructions, per_client_final_losses = fed_avg_attack(\n",
    "                        original_net=copy.deepcopy(net),\n",
    "                        attacked_clients_params=attacked_clients_params,\n",
    "                        attack_iterations=attack_iterations,\n",
    "                        attack_learning_rate=attack_learning_rate,\n",
    "                        n_local_epochs=n_local_epochs,\n",
    "                        local_batch_size=local_batch_size,\n",
    "                        lr=lr,\n",
    "                        dataset=dataset,\n",
    "                        per_client_ground_truth_data=per_client_ground_truth_data,\n",
    "                        per_client_ground_truth_labels=per_client_ground_truth_labels,\n",
    "                        reconstruction_loss=reconstruction_loss,\n",
    "                        priors=priors,\n",
    "                        epoch_matching_prior=epoch_matching_prior,\n",
    "                        initialization_mode=initialization_mode,\n",
    "                        softmax_trick=softmax_trick,\n",
    "                        gumbel_softmax_trick=gumbel_softmax_trick,\n",
    "                        sigmoid_trick=sigmoid_trick,\n",
    "                        temperature_mode=temperature_mode,\n",
    "                        sign_trick=sign_trick,\n",
    "                        apply_projection_to_features=fish_for_features,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                # enter the results in the collectors\n",
    "                for client_idx in range(len(attacked_clients)):\n",
    "                    per_client_all_reconstructions[client_idx].append(per_client_candidate_reconstructions[client_idx].detach().clone())\n",
    "                    if (per_client_best_scores[client_idx] is None) or (per_client_best_scores[client_idx] > per_client_final_losses[client_idx]):\n",
    "                        per_client_best_scores[client_idx] = per_client_final_losses[client_idx]\n",
    "                        per_client_best_reconstructions[client_idx] = per_client_candidate_reconstructions[client_idx].detach().clone()\n",
    "\n",
    "            if return_all:\n",
    "                per_global_epoch_per_client_reconstructions.append(per_client_all_reconstructions)\n",
    "            elif pooling is not None:\n",
    "                if perfect_pooling:\n",
    "                    per_client_pooled = [pooled_ensemble(all_reconstructions, ground_truth_data, dataset, pooling=pooling)\n",
    "                                        for all_reconstructions, ground_truth_data in zip(per_client_all_reconstructions, per_client_ground_truth_data)]\n",
    "                else:\n",
    "                    per_client_pooled = [pooled_ensemble(all_reconstructions, best_reconstruction, dataset, pooling=pooling)\n",
    "                                        for all_reconstructions, best_reconstruction in zip(per_client_all_reconstructions, per_client_best_reconstructions)]\n",
    "                per_global_epoch_per_client_reconstructions.append(per_client_pooled)\n",
    "            else:\n",
    "                per_global_epoch_per_client_reconstructions.append(per_client_best_reconstructions)\n",
    "            per_global_epoch_per_client_ground_truth.append(per_client_ground_truth_data)\n",
    "            print(\"# -------------- ATTACK END -------------- #\")\n",
    "            # -------------- ATTACK END -------------- #\n",
    "\n",
    "        # Continue the training\n",
    "        # transpose the list\n",
    "        transposed_clients_params = [[] for _ in range(len(clients_params[0]))]\n",
    "        for client_params in clients_params:\n",
    "            for i, param in enumerate(client_params):\n",
    "                transposed_clients_params[i].append(param.clone().detach())\n",
    "\n",
    "        # aggregate the params using mean aggregation\n",
    "        # aggregated_params = [torch.mean(torch.stack(params_over_clients), dim=0) for params_over_clients in transposed_clients_params]\n",
    "\n",
    "        # # write the new parameters into the main network\n",
    "        # with torch.no_grad():\n",
    "        #     for param, agg_param in zip(net.parameters(), aggregated_params):\n",
    "        #         param.copy_(agg_param)\n",
    "        \n",
    "        # timer.end()\n",
    "    # timer.duration()\n",
    "\n",
    "    # random_baseline = calculate_random_baseline(dataset=dataset, recover_batch_sizes=reconstruction_batch_sizes,\n",
    "    #                                                     tolerance_map=tolerance_map, n_samples=n_samples, mode=mode,\n",
    "    #                                                     device=args.device)\n",
    "\n",
    "    return net, training_data, per_global_epoch_per_client_reconstructions, per_global_epoch_per_client_ground_truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b00fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f4fa092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Code::  NY\n",
      "training sample:: NY.data and len is 2000\n",
      "testing sample:: NY.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "10\n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "QAT training\n",
      "n_batches is 8\n",
      "local_epoch is 5\n",
      "QAT model is saved to 50_clients_data/clients_trained_model/qat_NY.pth\n",
      "QAT Model Size: 78.2861328125 KB\n",
      "quantized_net is being used for testing\n",
      "Quantized Model - Validation Accuracy: 0.7677, Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiragpandav/Downloads/tableak_FT/myenv3.8/lib/python3.8/site-packages/torch/quantization/observer.py:241: UserWarning: must run observer before calling calculate_qparams.                                        Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_NY.pth\n",
      "Quantized Model Size: 30.552734375 KB\n",
      "parallelized--OFF \n",
      "Original param shape: torch.Size([100, 10]), New param shape: torch.Size([100, 10])\n",
      "Original param shape: torch.Size([100]), New param shape: torch.Size([100])\n",
      "Original param shape: torch.Size([100, 100]), New param shape: torch.Size([100, 100])\n",
      "Original param shape: torch.Size([100]), New param shape: torch.Size([100])\n",
      "Original param shape: torch.Size([1, 100]), New param shape: torch.Size([1, 100])\n",
      "Original param shape: torch.Size([1]), New param shape: torch.Size([1])\n",
      "# -------------- ATTACK END -------------- #\n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 56.9% +- 0.00\n",
      "random_baseline (50.8, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "def calculate_fed_avg_local_dataset_inversion_performance(architecture_layout, dataset, max_client_dataset_size,\n",
    "                                                          local_epochs, local_batch_sizes, epoch_prior_params,\n",
    "                                                          tolerance_map, n_samples, config, max_n_cpus, first_cpu, device, state_name=\"AL\"):\n",
    "    \n",
    "    collected_data = np.zeros((len(local_epochs), len(local_batch_sizes), len(epoch_prior_params), 3, 5))\n",
    "\n",
    "    timer = Timer(len(local_epochs) * len(local_batch_sizes) * len(epoch_prior_params))\n",
    "    with open(f'50_clients_data/reconstr_and_GT/dataset_{state_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "\n",
    "    with open(f'50_clients_data/reconstr_and_GT/tolerance_map_{state_name}.pkl', 'wb') as f:        \n",
    "        pickle.dump(tolerance_map, f)   \n",
    "        \n",
    "    for i, lepochs in enumerate(local_epochs):\n",
    "        for j, lbatch_size in enumerate(local_batch_sizes):\n",
    "            for k, epoch_prior_param in enumerate(epoch_prior_params):\n",
    "                timer.start()                \n",
    "                print(timer)\n",
    "                print(dataset.num_features)\n",
    "                net = FullyConnected(dataset.num_features, architecture_layout)\n",
    "                # print(net)\n",
    "                epoch_matching_prior = (epoch_prior_param, config['epoch_matching_prior']) if epoch_prior_param > 0. else None\n",
    "\n",
    "                _, _, reconstructions, ground_truths= train_and_attack_fed_avg(\n",
    "                    net=net,\n",
    "                    n_clients=n_samples,\n",
    "                    n_global_epochs=config['n_global_epochs'],\n",
    "                    n_local_epochs=lepochs,\n",
    "                    local_batch_size=lbatch_size,\n",
    "                    lr=config['lr'],\n",
    "                    dataset=dataset,\n",
    "                    shuffle=config['shuffle'],\n",
    "                    attacked_clients=config['attacked_clients'],\n",
    "                    attack_iterations=config['attack_iterations'],\n",
    "                    reconstruction_loss=config['reconstruction_loss'],\n",
    "                    priors=config['priors'],\n",
    "                    epoch_matching_prior=epoch_matching_prior,\n",
    "                    post_selection=config['post_selection'],\n",
    "                    attack_learning_rate=config['attack_learning_rate'],\n",
    "                    return_all=config['return_all'],\n",
    "                    pooling=config['pooling'],\n",
    "                    perfect_pooling=config['perfect_pooling'],\n",
    "                    initialization_mode=config['initialization_mode'],\n",
    "                    softmax_trick=config['softmax_trick'],\n",
    "                    gumbel_softmax_trick=config['gumbel_softmax_trick'],\n",
    "                    sigmoid_trick=config['sigmoid_trick'],\n",
    "                    temperature_mode=config['temperature_mode'],\n",
    "                    sign_trick=config['sign_trick'],\n",
    "                    fish_for_features=None,\n",
    "                    max_n_cpus=max_n_cpus,\n",
    "                    first_cpu=first_cpu,\n",
    "                    device=device,\n",
    "                    verbose=False,\n",
    "                    max_client_dataset_size=max_client_dataset_size,\n",
    "                    parallelized=False,\n",
    "                    state_name=state_name\n",
    "                )\n",
    "                all_errors = []\n",
    "                cat_errors = []\n",
    "                cont_errors = []\n",
    "                \n",
    "                with open(f'50_clients_data/reconstr_and_GT/reconstructions_ground_truths_{state_name}.pkl', 'wb') as f:\n",
    "                        pickle.dump({'reconstructions': reconstructions, 'ground_truths': ground_truths}, f)\n",
    "                \n",
    "                print(\"reconstructions_and_ground_truths is dumped\")\n",
    "\n",
    "\n",
    "                for epoch_reconstruction, epoch_ground_truth in zip(reconstructions, ground_truths):\n",
    "                    for client_reconstruction, client_ground_truth in zip(epoch_reconstruction, epoch_ground_truth):\n",
    "                        if config['post_process_cont']:\n",
    "                            client_reconstruction = post_process_continuous(client_reconstruction, dataset=dataset)\n",
    "                        client_recon_projected, client_gt_projected = dataset.decode_batch(client_reconstruction, standardized=True), dataset.decode_batch(client_ground_truth, standardized=True)\n",
    "                        _, batch_cost_all, batch_cost_cat, batch_cost_cont = match_reconstruction_ground_truth(client_gt_projected, client_recon_projected, tolerance_map)\n",
    "                        all_errors.append(np.mean(batch_cost_all))\n",
    "                        cat_errors.append(np.mean(batch_cost_cat))\n",
    "                        cont_errors.append(np.mean(batch_cost_cont))\n",
    "\n",
    "                collected_data[i, j, k, 0] = np.mean(all_errors), np.std(all_errors), np.median(all_errors), np.min(all_errors), np.max(all_errors)\n",
    "                collected_data[i, j, k, 1] = np.mean(cat_errors), np.std(cat_errors), np.median(cat_errors), np.min(cat_errors), np.max(cat_errors)\n",
    "                collected_data[i, j, k, 2] = np.mean(cont_errors), np.std(cont_errors), np.median(cont_errors), np.min(cont_errors), np.max(cont_errors)\n",
    "\n",
    "                timer.end()\n",
    "\n",
    "            best_param_index = np.argmin(collected_data[i, j, :, 0, 0]).item()\n",
    "\n",
    "            print(f'Performance at {lepochs} Epochs and {lbatch_size} Batch Size: {100*(1-collected_data[i, j, best_param_index, 0, 0]):.1f}% +- {100*collected_data[i, j, best_param_index, 0, 1]:.2f}')\n",
    "            \n",
    "            display_map = {\n",
    "                'mean': 0,\n",
    "                'std': 1,\n",
    "                'median': 2,\n",
    "                'min': 3,\n",
    "                'max': 4\n",
    "            }\n",
    "            display = 'mean'\n",
    "            random_baseline = calculate_random_baseline(dataset=dataset, recover_batch_sizes=[lbatch_size],\n",
    "                                                        tolerance_map=tolerance_map, n_samples=n_samples)\n",
    "            batch_sizes = [lbatch_size]\n",
    "            # print(\"random acc:  \",random_baseline)\n",
    "            for l, batch_size in enumerate(batch_sizes):\n",
    "                print(\"random_baseline\", (np.around(100 - 100*random_baseline[l, 0, display_map[display]], 1), np.around(100*random_baseline[l, 0, 1], 1)))\n",
    "\n",
    "def main(args):\n",
    "    datasets = {\n",
    "        'ADULT': ADULT,\n",
    "    }\n",
    "\n",
    "    configs = {\n",
    "        0: {\n",
    "            'n_global_epochs': 1,\n",
    "            'lr': 0.01,\n",
    "            'shuffle': True,\n",
    "            'attacked_clients': 'all',\n",
    "            'attack_iterations': 1500,\n",
    "            'reconstruction_loss': 'cosine_sim',\n",
    "            'priors': None,\n",
    "            'epoch_matching_prior': 'mean_squared_error',\n",
    "            'post_selection': 1,\n",
    "            'attack_learning_rate': 0.06,\n",
    "            'return_all': False,\n",
    "            'pooling': None,\n",
    "            'perfect_pooling': False,\n",
    "            'initialization_mode': 'uniform',\n",
    "            'softmax_trick': False,\n",
    "            'gumbel_softmax_trick': False,\n",
    "            'sigmoid_trick': False,\n",
    "            'temperature_mode': 'constant',\n",
    "            'sign_trick': True,\n",
    "            'verbose': False,\n",
    "            'max_client_dataset_size': 32,\n",
    "            'post_process_cont': False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    architecture_layout = [100, 100, 2]  \n",
    "    max_client_dataset_size = 2000\n",
    "    local_epochs =[5]\n",
    "    local_batch_sizes = [250]\n",
    "    epoch_prior_params =[0.01]\n",
    "    tol = 0.319\n",
    "\n",
    "    config = configs[0]\n",
    "    # dataset = ADULT(device=\"cpu\", random_state=2, name_state=\"AL\")\n",
    "    dataset = ADULT(device=\"cpu\", random_state=42,name_state=args.name_state)\n",
    "\n",
    "    dataset.standardize()\n",
    "    tolerance_map = dataset.create_tolerance_map(tol=tol)\n",
    "\n",
    "    np.random.seed(2)\n",
    "    torch.manual_seed(2)\n",
    "\n",
    "    base_path = f'experiment_data/fedavg_experiments/ADULT/experiment_0'\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    specific_file_path = base_path + f'/inversion_data_all_0_ADULT_1_{epoch_prior_params}_{tol}_2_{args.name_state}.npy'\n",
    "\n",
    "    if os.path.isfile(specific_file_path):\n",
    "        print('This experiment has already been conducted')\n",
    "        os.remove(specific_file_path)\n",
    "        print(f'File {specific_file_path} has been removed.')\n",
    "    else:\n",
    "        inversion_data = calculate_fed_avg_local_dataset_inversion_performance(\n",
    "            architecture_layout=architecture_layout,\n",
    "            dataset=dataset,\n",
    "            max_client_dataset_size=max_client_dataset_size,\n",
    "            local_epochs=local_epochs,\n",
    "            local_batch_sizes=local_batch_sizes,\n",
    "            epoch_prior_params=epoch_prior_params,\n",
    "            tolerance_map=tolerance_map,\n",
    "            n_samples=1,\n",
    "            config=config,\n",
    "            max_n_cpus=4,\n",
    "            first_cpu=0,\n",
    "            device=\"cpu\",\n",
    "            state_name=args.name_state\n",
    "        )\n",
    "        np.save(specific_file_path, inversion_data)\n",
    "    print('Complete                           ')\n",
    "    print('==================================================================')\n",
    "    print('==================================================================')\n",
    "\n",
    "import argparse\n",
    "\n",
    "# state_name = [\"AK\",\"AZ\",\"AR\",\"CA\",\"ID\",\"NH\",\"NM\",\"NY\"]\n",
    "state_name = [\"NY\"]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    if 'ipykernel' in sys.modules:  # Check if running in Jupyter Notebook\n",
    "        class Args:\n",
    "            def __init__(self, name_state):\n",
    "                self.name_state = name_state\n",
    "    else:\n",
    "        import argparse\n",
    "        parser = argparse.ArgumentParser('run_inversion_parser')\n",
    "        parser.add_argument('--name_state', type=str, default='CA', help='State Code')\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    for state in state_name:\n",
    "        if 'ipykernel' in sys.modules:\n",
    "            args = Args(name_state=state) \n",
    "        else:\n",
    "            args.name_state = state\n",
    "        main(args)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa2b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d1464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06459d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUANTIZED\n",
    "\n",
    "# AK: Performance at 5 Epochs and 250 Batch Size: 55.3% +- 0.00  - from 66.50%\n",
    "# AR: Performance at 5 Epochs and 250 Batch Size: 51.0% +- 0.00  - from 72.8% \n",
    "# AZ: Performance at 5 Epochs and 250 Batch Size: 63.4% +- 0.00  - from 69.90%\n",
    "# CA: Performance at 5 Epochs and 250 Batch Size: 65.1% +- 0.00  - from 68.40% \n",
    "# ID: Performance at 5 Epochs and 250 Batch Size: 60.2% +- 0.00  - from 71.50%\n",
    "# NH: Performance at 5 Epochs and 250 Batch Size: 59.4% +- 0.00  - from 71.70%\n",
    "# NM: Performance at 5 Epochs and 250 Batch Size: 62.9% +- 0.00  - from 72.50%\n",
    "# NY: Performance at 5 Epochs and 250 Batch Size: 56.9% +- 0.00  - from 67.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0af3dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AK: Performance at 5 Epochs and 250 Batch Size: 66.7% +- 0.00   - from 73%\n",
    "# AZ: Performance at 5 Epochs and 250 Batch Size: 66.6% +- 0.00 -  from 70%\n",
    "# AR: Performance at 5 Epochs and 250 Batch Size: 69.2% +- 0.00 -  from 73.08%\n",
    "# CA: Performance at 5 Epochs and 250 Batch Size: 67.1% +- 0.00  - from 68.98 \n",
    "# ID: Performance at 5 Epochs and 250 Batch Size: 68.5% +- 0.00  - from 72.22%\n",
    "# NH: Performance at 5 Epochs and 250 Batch Size: 66.3% +- 0.00  - from 71.59\n",
    "# NM: Performance at 5 Epochs and 250 Batch Size: 69.3% +- 0.00  - from 72.11\n",
    "# NY: Performance at 5 Epochs and 250 Batch Size: 64.7% +- 0.00 -  from 67.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d393b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d96a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1522b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bb134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63c0212d",
   "metadata": {},
   "source": [
    "# Post quantization traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ab224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    A linear layer followed by a ReLU activation layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(LinReLU, self).__init__()\n",
    "        self.linear = nn.Linear(in_size, out_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layers = nn.Sequential(self.linear, self.relu)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.linear.reset_parameters()\n",
    "        return self\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple fully connected neural network with ReLU activations.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, layout):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        layers = [nn.Flatten()]\n",
    "        prev_fc_size = input_size\n",
    "        for i, fc_size in enumerate(layout):\n",
    "            if i + 1 < len(layout):\n",
    "                layers += [LinReLU(prev_fc_size, fc_size)]\n",
    "            else:\n",
    "                layers += [nn.Linear(prev_fc_size, 1), nn.Sigmoid()]\n",
    "            prev_fc_size = fc_size\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        \"\"\"\n",
    "        Fuses Linear and ReLU layers in LinReLU modules\n",
    "        \"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, LinReLU):\n",
    "                torch.quantization.fuse_modules(\n",
    "                    module.layers, \n",
    "                    ['0', '1'],  # Fuse first (Linear) and second (ReLU) \n",
    "                    inplace=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b88d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_attack_fed_avg(net, n_clients, n_global_epochs, n_local_epochs, local_batch_size, lr, dataset, shuffle=False,\n",
    "                             attacked_clients=None, attack_iterations=1000, reconstruction_loss='cosine_sim', priors=None,\n",
    "                             epoch_matching_prior=None, post_selection=1, attack_learning_rate=0.06, return_all=False,\n",
    "                             pooling=None, perfect_pooling=False, initialization_mode='uniform', softmax_trick=True,\n",
    "                             gumbel_softmax_trick=False, sigmoid_trick=False, temperature_mode='constant',\n",
    "                             sign_trick=True, fish_for_features=None, device=None, verbose=False, max_n_cpus=50, first_cpu=0,\n",
    "                             max_client_dataset_size=None, parallelized=False, metadata_path='metadata', state_name=\"AL\"):\n",
    "\n",
    "    if device is None:\n",
    "        device = dataset.device\n",
    "\n",
    "    if attacked_clients is None:\n",
    "        attacked_clients = []\n",
    "    elif attacked_clients == 'all':\n",
    "        attacked_clients = list(np.arange(n_clients))\n",
    "\n",
    "    if max_client_dataset_size is None:\n",
    "        max_client_dataset_size = len(dataset)\n",
    "\n",
    "    per_global_epoch_per_client_reconstructions = []\n",
    "    per_global_epoch_per_client_ground_truth = []\n",
    "    training_data = np.zeros((n_global_epochs, 2))\n",
    "    \n",
    "\n",
    "    # Split data into client datasets\n",
    "    if shuffle:\n",
    "        dataset.shuffle()\n",
    "\n",
    "    Xtrain, ytrain = dataset.get_Xtrain(), dataset.get_ytrain()\n",
    "    split_size = min(max_client_dataset_size, int(np.ceil(Xtrain.size()[0] / n_clients)))\n",
    "    Xtrain_splits = [Xtrain[i*split_size:min(int(Xtrain.size()[0]), (i+1)*split_size)].clone().detach() for i in range(n_clients)]\n",
    "    ytrain_splits = [ytrain[i*split_size:min(int(Xtrain.size()[0]), (i+1)*split_size)].clone().detach() for i in range(n_clients)]\n",
    "\n",
    "    # Loss function\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    timer = Timer(n_global_epochs)\n",
    "    # Load pre-trained model\n",
    "    pre_trained_model_path = \"50_clients_data/clients_trained_model/pre_trained_model.pth\"\n",
    "    state_dict = torch.load(pre_trained_model_path)\n",
    "    weights_dict = {k: v for k, v in state_dict.items() if 'weight' in k}\n",
    "    net.load_state_dict(weights_dict, strict=False)\n",
    "    print(\"Pre-trained model loaded.\")\n",
    "\n",
    "    # Helper to quantize the model\n",
    "    # def quantize_model(model, calibration_data, backend='qnnpack'):\n",
    "    #     model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "    #     torch.backends.quantized.engine = backend\n",
    "\n",
    "    #     # Prepare model (add observers)\n",
    "    #     quantized_model = torch.quantization.prepare(model, inplace=False)\n",
    "\n",
    "    #     # Calibration step\n",
    "    #     with torch.no_grad():\n",
    "    #         for batch_X in calibration_data:\n",
    "    #             quantized_model(batch_X)\n",
    "\n",
    "    #     # Convert to quantized model\n",
    "    #     quantized_model = torch.quantization.convert(quantized_model, inplace=False)\n",
    "    #     return quantized_model\n",
    "    \n",
    "    def quantize_model(model, calibration_data, backend='qnnpack'):\n",
    "        model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "        torch.backends.quantized.engine = backend\n",
    "        model.fuse_model()\n",
    "    \n",
    "        # Prepare model (add observers)\n",
    "        quantized_model = torch.quantization.prepare(model, inplace=False)\n",
    "    \n",
    "        # Calibration step\n",
    "        with torch.no_grad():\n",
    "            for batch_X in calibration_data:\n",
    "                quantized_model(batch_X)\n",
    "    \n",
    "        # Convert to quantized model\n",
    "        quantized_model = torch.quantization.convert(quantized_model, inplace=False)\n",
    "        return quantized_model\n",
    "\n",
    "    # Training loop\n",
    "    for global_epoch in range(n_global_epochs):\n",
    "        acc, bac = get_acc_and_bac(net, dataset.get_Xtest(), dataset.get_ytest())\n",
    "        if verbose:\n",
    "            print(f'Global Epochs: {global_epoch + 1}/{n_global_epochs}    Acc: {acc * 100:.2f}%    BAcc: {bac * 100:.2f}%')\n",
    "\n",
    "        training_data[global_epoch] = acc, bac\n",
    "\n",
    "        # Create client networks\n",
    "        client_nets = [copy.deepcopy(net) for _ in range(n_clients)]\n",
    "\n",
    "        for client, (client_X, client_y, client_net) in enumerate(zip(Xtrain_splits, ytrain_splits, client_nets)):\n",
    "            n_batches = int(np.ceil(client_X.size()[0] / local_batch_size))\n",
    "\n",
    "            print(f\"Training client {client + 1}/{n_clients}\")\n",
    "            print(\"Normal training\")\n",
    "            print(\"n_batches is\",n_batches)\n",
    "            print(\"local_epoch is \",n_local_epochs)\n",
    "            for local_epoch in range(n_local_epochs):\n",
    "                for b in range(n_batches):\n",
    "                    current_batch_X = client_X[b * local_batch_size:min(int(client_X.size()[0]), (b+1)*local_batch_size)].clone().detach()\n",
    "                    current_batch_y = client_y[b * local_batch_size:min(int(client_X.size()[0]), (b+1)*local_batch_size)].clone().detach()\n",
    "                    outputs = client_net(current_batch_X)\n",
    "\n",
    "                    current_batch_y = current_batch_y.unsqueeze(1).float()\n",
    "                    loss = criterion(outputs, current_batch_y)\n",
    "                    grad = torch.autograd.grad(loss, client_net.parameters(), retain_graph=True)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        for param, param_grad in zip(client_net.parameters(), grad):\n",
    "                            param -= lr * param_grad\n",
    "            \n",
    "            client_net.eval()\n",
    "            val_running_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            inputs, labels = dataset.get_Xtest(), dataset.get_ytest()\n",
    "            labels = labels.unsqueeze(1).float()\n",
    "            val_n_batches = int(np.ceil(inputs.size()[0] / local_batch_size))\n",
    "            with torch.no_grad():\n",
    "                for b in range(val_n_batches):\n",
    "                    val_batch_X = inputs[b * local_batch_size:min(int(inputs.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "                    val_batch_y = labels[b * local_batch_size:min(int(labels.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "\n",
    "                    outputs = client_net(val_batch_X)\n",
    "                    val_loss = criterion(outputs, val_batch_y)\n",
    "                    val_running_loss += val_loss.item()\n",
    "\n",
    "                    predicted_classes = (outputs > 0.5).float()\n",
    "                    val_correct += (predicted_classes == val_batch_y).sum().item()\n",
    "                    val_total += val_batch_y.size(0)\n",
    "\n",
    "            val_epoch_loss = val_running_loss / len(inputs)\n",
    "            val_accuracy = val_correct / val_total\n",
    "            print(f\"Original Model - Validation Accuracy: {val_accuracy:.4f}, Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "            # Save the quantized model\n",
    "            model_path = f\"50_clients_data/clients_trained_model/{state_name}.pth\"\n",
    "            torch.save(client_net.state_dict(), model_path)\n",
    "            print(f\"Original model for client {client + 1} saved to {model_path}\")\n",
    "            print(\"Original Model Size:\", os.path.getsize(model_path) / 1024, \"KB\")\n",
    "            \n",
    "            # Quantization step\n",
    "            print(f\"Quantizing model for client {client + 1}\")\n",
    "            calibration_data = [\n",
    "                client_X[b * local_batch_size:min(int(client_X.size()[0]), (b+1)*local_batch_size)].clone().detach()\n",
    "                for b in range(n_batches)\n",
    "            ]\n",
    "\n",
    "            quantized_net = quantize_model(client_net, calibration_data)\n",
    "\n",
    "            quantized_net.eval()\n",
    "            val_running_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            inputs, labels = dataset.get_Xtest(), dataset.get_ytest()\n",
    "            labels = labels.unsqueeze(1).float()\n",
    "            val_n_batches = int(np.ceil(inputs.size()[0] / local_batch_size))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for b in range(val_n_batches):\n",
    "                    val_batch_X = inputs[b * local_batch_size:min(int(inputs.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "                    val_batch_y = labels[b * local_batch_size:min(int(labels.size()[0]), (b + 1) * local_batch_size)].clone().detach()\n",
    "\n",
    "                    outputs = quantized_net(val_batch_X)\n",
    "                    val_loss = criterion(outputs, val_batch_y)\n",
    "                    val_running_loss += val_loss.item()\n",
    "\n",
    "                    predicted_classes = (outputs > 0.5).float()\n",
    "                    val_correct += (predicted_classes == val_batch_y).sum().item()\n",
    "                    val_total += val_batch_y.size(0)\n",
    "\n",
    "            val_epoch_loss = val_running_loss / len(inputs)\n",
    "            val_accuracy = val_correct / val_total\n",
    "            print(f\"Quantized Model - Validation Accuracy: {val_accuracy:.4f}, Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "            # Save the quantized model\n",
    "            model_path = f\"50_clients_data/clients_trained_model/quantized_{state_name}.pth\"\n",
    "            torch.save(quantized_net.state_dict(), model_path)\n",
    "            \n",
    "            print(\"Quantized Model Size:\", os.path.getsize(model_path) / 1024, \"KB\")\n",
    "            \n",
    "            print(f\"Quantized model saved to {model_path}\")\n",
    "\n",
    "        quantization_flag= True\n",
    "        if quantization_flag is True:\n",
    "            print(\"Attack on quantized_net\")\n",
    "            clients_params = [[param.clone().detach() for param in quantized_net.parameters()] for quantized_net in client_nets]\n",
    "        else:\n",
    "            clients_params = [[param.clone().detach() for param in client_net.parameters()] for client_net in client_nets]\n",
    "\n",
    "        attack_bool= True\n",
    "        if attack_bool is False:\n",
    "            print(\"---------------------------------------\")\n",
    "            print(\"-----Attack Is NOT Being Applied-------\")\n",
    "            print(\"---------------------------------------\")\n",
    "            break\n",
    "        else:\n",
    "            # -------------- ATTACK -------------- #\n",
    "            per_client_all_reconstructions = [[] for _ in range(len(attacked_clients))]\n",
    "            per_client_best_reconstructions = [None for _ in range(len(attacked_clients))]\n",
    "            per_client_best_scores = [None for _ in range(len(attacked_clients))]\n",
    "            per_client_ground_truth_data = [Xtrain_splits[attacked_client].detach().clone() for attacked_client in attacked_clients]\n",
    "            per_client_ground_truth_labels = [ytrain_splits[attacked_client].detach().clone() for attacked_client in attacked_clients]\n",
    "            attacked_clients_params = [[param.clone().detach() for param in clients_params[attacked_client]] for attacked_client in attacked_clients]\n",
    "\n",
    "            for _ in range(post_selection):\n",
    "\n",
    "                if parallelized:\n",
    "                    print(\"parallelized\")\n",
    "                    per_client_candidate_reconstructions, per_client_final_losses = fed_avg_attack_parallelized_over_clients(\n",
    "                        original_net=copy.deepcopy(net),\n",
    "                        attacked_clients_params=attacked_clients_params,\n",
    "                        attack_iterations=attack_iterations,\n",
    "                        attack_learning_rate=attack_learning_rate,\n",
    "                        n_local_epochs=n_local_epochs,\n",
    "                        local_batch_size=local_batch_size,\n",
    "                        lr=lr,\n",
    "                        dataset=dataset,\n",
    "                        per_client_ground_truth_data=per_client_ground_truth_data,\n",
    "                        per_client_ground_truth_labels=per_client_ground_truth_labels,\n",
    "                        reconstruction_loss=reconstruction_loss,\n",
    "                        priors=priors,\n",
    "                        epoch_matching_prior=epoch_matching_prior,\n",
    "                        initialization_mode=initialization_mode,\n",
    "                        softmax_trick=softmax_trick,\n",
    "                        gumbel_softmax_trick=gumbel_softmax_trick,\n",
    "                        sigmoid_trick=sigmoid_trick,\n",
    "                        temperature_mode=temperature_mode,\n",
    "                        sign_trick=sign_trick,\n",
    "                        apply_projection_to_features=fish_for_features,\n",
    "                        max_n_cpus=max_n_cpus,\n",
    "                        first_cpu=first_cpu,\n",
    "                        device=device,\n",
    "                        metadata_path=metadata_path\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    print(\"parallelized--OFF \")\n",
    "                    per_client_candidate_reconstructions, per_client_final_losses = fed_avg_attack(\n",
    "                        original_net=copy.deepcopy(net),\n",
    "                        attacked_clients_params=attacked_clients_params,\n",
    "                        attack_iterations=attack_iterations,\n",
    "                        attack_learning_rate=attack_learning_rate,\n",
    "                        n_local_epochs=n_local_epochs,\n",
    "                        local_batch_size=local_batch_size,\n",
    "                        lr=lr,\n",
    "                        dataset=dataset,\n",
    "                        per_client_ground_truth_data=per_client_ground_truth_data,\n",
    "                        per_client_ground_truth_labels=per_client_ground_truth_labels,\n",
    "                        reconstruction_loss=reconstruction_loss,\n",
    "                        priors=priors,\n",
    "                        epoch_matching_prior=epoch_matching_prior,\n",
    "                        initialization_mode=initialization_mode,\n",
    "                        softmax_trick=softmax_trick,\n",
    "                        gumbel_softmax_trick=gumbel_softmax_trick,\n",
    "                        sigmoid_trick=sigmoid_trick,\n",
    "                        temperature_mode=temperature_mode,\n",
    "                        sign_trick=sign_trick,\n",
    "                        apply_projection_to_features=fish_for_features,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                # enter the results in the collectors\n",
    "                for client_idx in range(len(attacked_clients)):\n",
    "                    per_client_all_reconstructions[client_idx].append(per_client_candidate_reconstructions[client_idx].detach().clone())\n",
    "                    if (per_client_best_scores[client_idx] is None) or (per_client_best_scores[client_idx] > per_client_final_losses[client_idx]):\n",
    "                        per_client_best_scores[client_idx] = per_client_final_losses[client_idx]\n",
    "                        per_client_best_reconstructions[client_idx] = per_client_candidate_reconstructions[client_idx].detach().clone()\n",
    "\n",
    "            if return_all:\n",
    "                per_global_epoch_per_client_reconstructions.append(per_client_all_reconstructions)\n",
    "            elif pooling is not None:\n",
    "                if perfect_pooling:\n",
    "                    per_client_pooled = [pooled_ensemble(all_reconstructions, ground_truth_data, dataset, pooling=pooling)\n",
    "                                        for all_reconstructions, ground_truth_data in zip(per_client_all_reconstructions, per_client_ground_truth_data)]\n",
    "                else:\n",
    "                    per_client_pooled = [pooled_ensemble(all_reconstructions, best_reconstruction, dataset, pooling=pooling)\n",
    "                                        for all_reconstructions, best_reconstruction in zip(per_client_all_reconstructions, per_client_best_reconstructions)]\n",
    "                per_global_epoch_per_client_reconstructions.append(per_client_pooled)\n",
    "            else:\n",
    "                per_global_epoch_per_client_reconstructions.append(per_client_best_reconstructions)\n",
    "            per_global_epoch_per_client_ground_truth.append(per_client_ground_truth_data)\n",
    "            # -------------- ATTACK END -------------- #\n",
    "\n",
    "        # Continue the training\n",
    "        # transpose the list\n",
    "        transposed_clients_params = [[] for _ in range(len(clients_params[0]))]\n",
    "        for client_params in clients_params:\n",
    "            for i, param in enumerate(client_params):\n",
    "                transposed_clients_params[i].append(param.clone().detach())\n",
    "\n",
    "        # aggregate the params using mean aggregation\n",
    "        aggregated_params = [torch.mean(torch.stack(params_over_clients), dim=0) for params_over_clients in transposed_clients_params]\n",
    "\n",
    "        # write the new parameters into the main network\n",
    "        with torch.no_grad():\n",
    "            for param, agg_param in zip(net.parameters(), aggregated_params):\n",
    "                param.copy_(agg_param)\n",
    "        \n",
    "        # timer.end()\n",
    "    # timer.duration()\n",
    "\n",
    "    # random_baseline = calculate_random_baseline(dataset=dataset, recover_batch_sizes=reconstruction_batch_sizes,\n",
    "    #                                                     tolerance_map=tolerance_map, n_samples=n_samples, mode=mode,\n",
    "    #                                                     device=args.device)\n",
    "\n",
    "    return net, training_data, per_global_epoch_per_client_reconstructions, per_global_epoch_per_client_ground_truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5530dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19d46310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Code::  AK\n",
      "training sample:: AK.data and len is 2000\n",
      "testing sample:: AK.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "Normal training\n",
      "n_batches is 8\n",
      "local_epoch is  5\n",
      "Original Model - Validation Accuracy: 0.7475, Loss: 0.0049\n",
      "Original model for client 1 saved to 50_clients_data/clients_trained_model/AK.pth\n",
      "Original Model Size: 47.0634765625 KB\n",
      "Quantizing model for client 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W TensorImpl.h:848] Warning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model - Validation Accuracy: 0.7475, Loss: 0.0049\n",
      "Quantized Model Size: 30.5478515625 KB\n",
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_AK.pth\n",
      "Attack on quantized_net\n",
      "parallelized--OFF \n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 66.5% +- 0.00\n",
      "random_baseline (51.1, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n",
      "State Code::  AZ\n",
      "training sample:: AZ.data and len is 2000\n",
      "testing sample:: AZ.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "Normal training\n",
      "n_batches is 8\n",
      "local_epoch is  5\n",
      "Original Model - Validation Accuracy: 0.8384, Loss: 0.0047\n",
      "Original model for client 1 saved to 50_clients_data/clients_trained_model/AZ.pth\n",
      "Original Model Size: 47.06640625 KB\n",
      "Quantizing model for client 1\n",
      "Quantized Model - Validation Accuracy: 0.8283, Loss: 0.0048\n",
      "Quantized Model Size: 30.5546875 KB\n",
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_AZ.pth\n",
      "Attack on quantized_net\n",
      "parallelized--OFF \n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 69.9% +- 0.00\n",
      "random_baseline (50.1, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n",
      "State Code::  AR\n",
      "training sample:: AR.data and len is 2000\n",
      "testing sample:: AR.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "Normal training\n",
      "n_batches is 8\n",
      "local_epoch is  5\n",
      "Original Model - Validation Accuracy: 0.7475, Loss: 0.0046\n",
      "Original model for client 1 saved to 50_clients_data/clients_trained_model/AR.pth\n",
      "Original Model Size: 47.0654296875 KB\n",
      "Quantizing model for client 1\n",
      "Quantized Model - Validation Accuracy: 0.7475, Loss: 0.0046\n",
      "Quantized Model Size: 30.552734375 KB\n",
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_AR.pth\n",
      "Attack on quantized_net\n",
      "parallelized--OFF \n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 72.8% +- 0.00\n",
      "random_baseline (51.2, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n",
      "State Code::  CA\n",
      "training sample:: CA.data and len is 2000\n",
      "testing sample:: CA.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "Normal training\n",
      "n_batches is 8\n",
      "local_epoch is  5\n",
      "Original Model - Validation Accuracy: 0.7980, Loss: 0.0047\n",
      "Original model for client 1 saved to 50_clients_data/clients_trained_model/CA.pth\n",
      "Original Model Size: 47.064453125 KB\n",
      "Quantizing model for client 1\n",
      "Quantized Model - Validation Accuracy: 0.7980, Loss: 0.0048\n",
      "Quantized Model Size: 30.560546875 KB\n",
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_CA.pth\n",
      "Attack on quantized_net\n",
      "parallelized--OFF \n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 68.4% +- 0.00\n",
      "random_baseline (52.1, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n",
      "State Code::  ID\n",
      "training sample:: ID.data and len is 2000\n",
      "testing sample:: ID.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "Normal training\n",
      "n_batches is 8\n",
      "local_epoch is  5\n",
      "Original Model - Validation Accuracy: 0.7475, Loss: 0.0044\n",
      "Original model for client 1 saved to 50_clients_data/clients_trained_model/ID.pth\n",
      "Original Model Size: 47.0654296875 KB\n",
      "Quantizing model for client 1\n",
      "Quantized Model - Validation Accuracy: 0.7475, Loss: 0.0044\n",
      "Quantized Model Size: 30.5595703125 KB\n",
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_ID.pth\n",
      "Attack on quantized_net\n",
      "parallelized--OFF \n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 71.5% +- 0.00\n",
      "random_baseline (50.4, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n",
      "State Code::  NH\n",
      "training sample:: NH.data and len is 2000\n",
      "testing sample:: NH.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "Normal training\n",
      "n_batches is 8\n",
      "local_epoch is  5\n",
      "Original Model - Validation Accuracy: 0.6970, Loss: 0.0046\n",
      "Original model for client 1 saved to 50_clients_data/clients_trained_model/NH.pth\n",
      "Original Model Size: 47.0654296875 KB\n",
      "Quantizing model for client 1\n",
      "Quantized Model - Validation Accuracy: 0.7071, Loss: 0.0046\n",
      "Quantized Model Size: 30.5576171875 KB\n",
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_NH.pth\n",
      "Attack on quantized_net\n",
      "parallelized--OFF \n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 71.7% +- 0.00\n",
      "random_baseline (49.7, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n",
      "State Code::  NM\n",
      "training sample:: NM.data and len is 2000\n",
      "testing sample:: NM.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "Normal training\n",
      "n_batches is 8\n",
      "local_epoch is  5\n",
      "Original Model - Validation Accuracy: 0.7677, Loss: 0.0049\n",
      "Original model for client 1 saved to 50_clients_data/clients_trained_model/NM.pth\n",
      "Original Model Size: 47.0654296875 KB\n",
      "Quantizing model for client 1\n",
      "Quantized Model - Validation Accuracy: 0.7576, Loss: 0.0049\n",
      "Quantized Model Size: 30.5576171875 KB\n",
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_NM.pth\n",
      "Attack on quantized_net\n",
      "parallelized--OFF \n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 72.5% +- 0.00\n",
      "random_baseline (51.6, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n",
      "State Code::  NY\n",
      "training sample:: NY.data and len is 2000\n",
      "testing sample:: NY.test and len is 99\n",
      "0%: ??h ??m ??s          \n",
      "Pre-trained model loaded.\n",
      "Training client 1/1\n",
      "Normal training\n",
      "n_batches is 8\n",
      "local_epoch is  5\n",
      "Original Model - Validation Accuracy: 0.7677, Loss: 0.0048\n",
      "Original model for client 1 saved to 50_clients_data/clients_trained_model/NY.pth\n",
      "Original Model Size: 47.064453125 KB\n",
      "Quantizing model for client 1\n",
      "Quantized Model - Validation Accuracy: 0.7677, Loss: 0.0047\n",
      "Quantized Model Size: 30.5546875 KB\n",
      "Quantized model saved to 50_clients_data/clients_trained_model/quantized_NY.pth\n",
      "Attack on quantized_net\n",
      "parallelized--OFF \n",
      "reconstructions_and_ground_truths is dumped\n",
      "Performance at 5 Epochs and 250 Batch Size: 68.8% +- 0.00\n",
      "random_baseline (50.8, 0.0)\n",
      "Complete                           \n",
      "==================================================================\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "def calculate_fed_avg_local_dataset_inversion_performance(architecture_layout, dataset, max_client_dataset_size,\n",
    "                                                          local_epochs, local_batch_sizes, epoch_prior_params,\n",
    "                                                          tolerance_map, n_samples, config, max_n_cpus, first_cpu, device, state_name=\"AL\"):\n",
    "    \n",
    "    collected_data = np.zeros((len(local_epochs), len(local_batch_sizes), len(epoch_prior_params), 3, 5))\n",
    "\n",
    "    timer = Timer(len(local_epochs) * len(local_batch_sizes) * len(epoch_prior_params))\n",
    "    with open(f'50_clients_data/reconstr_and_GT/dataset_{state_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "\n",
    "    with open(f'50_clients_data/reconstr_and_GT/tolerance_map_{state_name}.pkl', 'wb') as f:        \n",
    "        pickle.dump(tolerance_map, f)   \n",
    "        \n",
    "    for i, lepochs in enumerate(local_epochs):\n",
    "        for j, lbatch_size in enumerate(local_batch_sizes):\n",
    "            for k, epoch_prior_param in enumerate(epoch_prior_params):\n",
    "                timer.start()                \n",
    "                print(timer)\n",
    "\n",
    "                net = FullyConnected(dataset.num_features, architecture_layout)\n",
    "\n",
    "                epoch_matching_prior = (epoch_prior_param, config['epoch_matching_prior']) if epoch_prior_param > 0. else None\n",
    "\n",
    "                _, _, reconstructions, ground_truths= train_and_attack_fed_avg(\n",
    "                    net=net,\n",
    "                    n_clients=n_samples,\n",
    "                    n_global_epochs=config['n_global_epochs'],\n",
    "                    n_local_epochs=lepochs,\n",
    "                    local_batch_size=lbatch_size,\n",
    "                    lr=config['lr'],\n",
    "                    dataset=dataset,\n",
    "                    shuffle=config['shuffle'],\n",
    "                    attacked_clients=config['attacked_clients'],\n",
    "                    attack_iterations=config['attack_iterations'],\n",
    "                    reconstruction_loss=config['reconstruction_loss'],\n",
    "                    priors=config['priors'],\n",
    "                    epoch_matching_prior=epoch_matching_prior,\n",
    "                    post_selection=config['post_selection'],\n",
    "                    attack_learning_rate=config['attack_learning_rate'],\n",
    "                    return_all=config['return_all'],\n",
    "                    pooling=config['pooling'],\n",
    "                    perfect_pooling=config['perfect_pooling'],\n",
    "                    initialization_mode=config['initialization_mode'],\n",
    "                    softmax_trick=config['softmax_trick'],\n",
    "                    gumbel_softmax_trick=config['gumbel_softmax_trick'],\n",
    "                    sigmoid_trick=config['sigmoid_trick'],\n",
    "                    temperature_mode=config['temperature_mode'],\n",
    "                    sign_trick=config['sign_trick'],\n",
    "                    fish_for_features=None,\n",
    "                    max_n_cpus=max_n_cpus,\n",
    "                    first_cpu=first_cpu,\n",
    "                    device=device,\n",
    "                    verbose=False,\n",
    "                    max_client_dataset_size=max_client_dataset_size,\n",
    "                    parallelized=False,\n",
    "                    state_name=state_name\n",
    "                )\n",
    "                all_errors = []\n",
    "                cat_errors = []\n",
    "                cont_errors = []\n",
    "                \n",
    "                with open(f'50_clients_data/reconstr_and_GT/reconstructions_ground_truths_{state_name}.pkl', 'wb') as f:\n",
    "                        pickle.dump({'reconstructions': reconstructions, 'ground_truths': ground_truths}, f)\n",
    "                \n",
    "                print(\"reconstructions_and_ground_truths is dumped\")\n",
    "\n",
    "\n",
    "                for epoch_reconstruction, epoch_ground_truth in zip(reconstructions, ground_truths):\n",
    "                    for client_reconstruction, client_ground_truth in zip(epoch_reconstruction, epoch_ground_truth):\n",
    "                        if config['post_process_cont']:\n",
    "                            client_reconstruction = post_process_continuous(client_reconstruction, dataset=dataset)\n",
    "                        client_recon_projected, client_gt_projected = dataset.decode_batch(client_reconstruction, standardized=True), dataset.decode_batch(client_ground_truth, standardized=True)\n",
    "                        _, batch_cost_all, batch_cost_cat, batch_cost_cont = match_reconstruction_ground_truth(client_gt_projected, client_recon_projected, tolerance_map)\n",
    "                        all_errors.append(np.mean(batch_cost_all))\n",
    "                        cat_errors.append(np.mean(batch_cost_cat))\n",
    "                        cont_errors.append(np.mean(batch_cost_cont))\n",
    "\n",
    "                collected_data[i, j, k, 0] = np.mean(all_errors), np.std(all_errors), np.median(all_errors), np.min(all_errors), np.max(all_errors)\n",
    "                collected_data[i, j, k, 1] = np.mean(cat_errors), np.std(cat_errors), np.median(cat_errors), np.min(cat_errors), np.max(cat_errors)\n",
    "                collected_data[i, j, k, 2] = np.mean(cont_errors), np.std(cont_errors), np.median(cont_errors), np.min(cont_errors), np.max(cont_errors)\n",
    "\n",
    "                timer.end()\n",
    "\n",
    "            best_param_index = np.argmin(collected_data[i, j, :, 0, 0]).item()\n",
    "\n",
    "            print(f'Performance at {lepochs} Epochs and {lbatch_size} Batch Size: {100*(1-collected_data[i, j, best_param_index, 0, 0]):.1f}% +- {100*collected_data[i, j, best_param_index, 0, 1]:.2f}')\n",
    "            \n",
    "            display_map = {\n",
    "                'mean': 0,\n",
    "                'std': 1,\n",
    "                'median': 2,\n",
    "                'min': 3,\n",
    "                'max': 4\n",
    "            }\n",
    "            display = 'mean'\n",
    "            random_baseline = calculate_random_baseline(dataset=dataset, recover_batch_sizes=[lbatch_size],\n",
    "                                                        tolerance_map=tolerance_map, n_samples=n_samples)\n",
    "            batch_sizes = [lbatch_size]\n",
    "            # print(\"random acc:  \",random_baseline)\n",
    "            for l, batch_size in enumerate(batch_sizes):\n",
    "                print(\"random_baseline\", (np.around(100 - 100*random_baseline[l, 0, display_map[display]], 1), np.around(100*random_baseline[l, 0, 1], 1)))\n",
    "\n",
    "def main(args):\n",
    "    datasets = {\n",
    "        'ADULT': ADULT,\n",
    "    }\n",
    "\n",
    "    configs = {\n",
    "        0: {\n",
    "            'n_global_epochs': 1,\n",
    "            'lr': 0.01,\n",
    "            'shuffle': True,\n",
    "            'attacked_clients': 'all',\n",
    "            'attack_iterations': 1500,\n",
    "            'reconstruction_loss': 'cosine_sim',\n",
    "            'priors': None,\n",
    "            'epoch_matching_prior': 'mean_squared_error',\n",
    "            'post_selection': 1,\n",
    "            'attack_learning_rate': 0.06,\n",
    "            'return_all': False,\n",
    "            'pooling': None,\n",
    "            'perfect_pooling': False,\n",
    "            'initialization_mode': 'uniform',\n",
    "            'softmax_trick': False,\n",
    "            'gumbel_softmax_trick': False,\n",
    "            'sigmoid_trick': False,\n",
    "            'temperature_mode': 'constant',\n",
    "            'sign_trick': True,\n",
    "            'verbose': False,\n",
    "            'max_client_dataset_size': 32,\n",
    "            'post_process_cont': False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    architecture_layout = [100, 100, 2]  \n",
    "    max_client_dataset_size = 2000\n",
    "    local_epochs =[5]\n",
    "    local_batch_sizes = [250]\n",
    "    epoch_prior_params =[0.01]\n",
    "    tol = 0.319\n",
    "\n",
    "    config = configs[0]\n",
    "    # dataset = ADULT(device=\"cpu\", random_state=2, name_state=\"AL\")\n",
    "    dataset = ADULT(device=\"cpu\", random_state=42,name_state=args.name_state)\n",
    "\n",
    "    dataset.standardize()\n",
    "    tolerance_map = dataset.create_tolerance_map(tol=tol)\n",
    "\n",
    "    np.random.seed(2)\n",
    "    torch.manual_seed(2)\n",
    "\n",
    "    base_path = f'experiment_data/fedavg_experiments/ADULT/experiment_0'\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    specific_file_path = base_path + f'/inversion_data_all_0_ADULT_1_{epoch_prior_params}_{tol}_2_{args.name_state}.npy'\n",
    "\n",
    "    if os.path.isfile(specific_file_path):\n",
    "        print('This experiment has already been conducted')\n",
    "        os.remove(specific_file_path)\n",
    "        print(f'File {specific_file_path} has been removed.')\n",
    "    else:\n",
    "        inversion_data = calculate_fed_avg_local_dataset_inversion_performance(\n",
    "            architecture_layout=architecture_layout,\n",
    "            dataset=dataset,\n",
    "            max_client_dataset_size=max_client_dataset_size,\n",
    "            local_epochs=local_epochs,\n",
    "            local_batch_sizes=local_batch_sizes,\n",
    "            epoch_prior_params=epoch_prior_params,\n",
    "            tolerance_map=tolerance_map,\n",
    "            n_samples=1,\n",
    "            config=config,\n",
    "            max_n_cpus=4,\n",
    "            first_cpu=0,\n",
    "            device=\"cpu\",\n",
    "            state_name=args.name_state\n",
    "        )\n",
    "        np.save(specific_file_path, inversion_data)\n",
    "    print('Complete                           ')\n",
    "    print('==================================================================')\n",
    "    print('==================================================================')\n",
    "\n",
    "import argparse\n",
    "# state_name=[\"AZ\",\"ID\"]\n",
    "# if __name__ == '__main__':\n",
    "#     import sys\n",
    "#     if 'ipykernel' in sys.modules:  # Check if running in Jupyter Notebook\n",
    "#         class Args:\n",
    "#             name_state = 'AZ'  \n",
    "#         args = Args()\n",
    "#     else:\n",
    "#         parser = argparse.ArgumentParser('run_inversion_parser')\n",
    "#         parser.add_argument('--name_state', type=str, default='CA', help='State Code')\n",
    "#         args = parser.parse_args()\n",
    "    \n",
    "#     main(args)\n",
    "\n",
    "# client_models = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "#                \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "#                \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "#                \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "#                \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "state_name = [\"AK\",\"AZ\",\"AR\",\"CA\", \"ID\",\"NH\",\"NM\",\"NY\"]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "    if 'ipykernel' in sys.modules:  # Check if running in Jupyter Notebook\n",
    "        class Args:\n",
    "            def __init__(self, name_state):\n",
    "                self.name_state = name_state\n",
    "    else:\n",
    "        import argparse\n",
    "        parser = argparse.ArgumentParser('run_inversion_parser')\n",
    "        parser.add_argument('--name_state', type=str, default='CA', help='State Code')\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    for state in state_name:\n",
    "        if 'ipykernel' in sys.modules:\n",
    "            args = Args(name_state=state)  # Create args for each state in the list\n",
    "        else:\n",
    "            args.name_state = state  # Modify the argument directly\n",
    "        main(args)  # Call main with the current state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a7fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AK: Performance at 5 Epochs and 250 Batch Size: 66.5% +- 0.00     - from 68.4%\n",
    "# AZ: Performance at 5 Epochs and 250 Batch Size: 69.9% +- 0.00     - from 70%\n",
    "# AR: Performance at 5 Epochs and 250 Batch Size: 72.8% +- 0.00     - from 73.08%\n",
    "# CA: Performance at 5 Epochs and 250 Batch Size: 68.4% +- 0.00      - from 68.98 \n",
    "# ID: Performance at 5 Epochs and 250 Batch Size: 71.5%  +- 0.00    - from 72.22%\n",
    "# NH: Performance at 5 Epochs and 250 Batch Size: 71.7% +- 0.00     - from 71.59\n",
    "# NM: Performance at 5 Epochs and 250 Batch Size: 72.5% +- 0.00     - from 72.11\n",
    "# NY: Performance at 5 Epochs and 250 Batch Size: 68.8% +- 0.00     - from 67.11\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a57c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##QAT\n",
    "\n",
    "# AK: Performance at 5 Epochs and 250 Batch Size: 69.2%/66.7%    - from 73%\n",
    "# AZ: Performance at 5 Epochs and 250 Batch Size: 66.6% +- 0.00  - from 70%\n",
    "# AR: Performance at 5 Epochs and 250 Batch Size: 69.2% +- 0.00  - from 73.08%\n",
    "# CA: Performance at 5 Epochs and 250 Batch Size: 67.1% +- 0.00  - from 68.98 \n",
    "# ID: Performance at 5 Epochs and 250 Batch Size: 68.5% +- 0.00  - from 72.22%\n",
    "# NH: Performance at 5 Epochs and 250 Batch Size: 66.3% +- 0.00  - from 71.59\n",
    "# NM: Performance at 5 Epochs and 250 Batch Size: 66.3% +- 0.00  - from 72.11\n",
    "# NY: Performance at 5 Epochs and 250 Batch Size: 64.7% +- 0.00 -  from 67.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23aa95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f9ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_models = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "#                \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "#                \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "#                \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "#                \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
