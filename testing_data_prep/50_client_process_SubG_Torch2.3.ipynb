{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2662e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8fb061-0f10-4ad9-ab36-1148ee49cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets.base_dataset import BaseDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import to_numeric\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7055a76-f724-4806-b51b-6db5fe4f5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADULT(BaseDataset):\n",
    "\n",
    "    def __init__(self, name='ADULT', single_bit_binary=False, device='cpu', random_state=42, name_state=\"CA\"):\n",
    "        super(ADULT, self).__init__(name=name, device=device, random_state=random_state)\n",
    "        print(name_state)\n",
    "        self.features = {\n",
    "            'AGEP': None,\n",
    "            'COW': None,\n",
    "            'SCHL': None,\n",
    "            'MAR': None,\n",
    "            'OCCP': None,\n",
    "            'POBP': None,\n",
    "            'RELP': None,\n",
    "            'WKHP': None,\n",
    "            'SEX': None,\n",
    "            'RAC1P': None,      \n",
    "            'PINCP': ['>50K', '<=50K']\n",
    "        }\n",
    "        \n",
    "        self.single_bit_binary = single_bit_binary\n",
    "        self.label = 'PINCP'\n",
    "\n",
    "        self.train_features = {key: self.features[key] for key in self.features.keys() if key != self.label}\n",
    "\n",
    "        # name_state=\"CA\"\n",
    "        # self.train_data_df = pd.read_csv(f'50_clients_data/client_subG_splits/{name_state}.data', delimiter=',', names=list(self.features.keys()), engine='python')        \n",
    "        # self.test_data_df = pd.read_csv(f'50_clients_data/client_subG_splits/{name_state}.test', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "\n",
    "\n",
    "        self.train_data_df = pd.read_csv(f'50_clients_data_testing/raw_data/testing.data', delimiter=',', names=list(self.features.keys()), engine='python')        \n",
    "        self.test_data_df = pd.read_csv(f'50_clients_data_testing/raw_data/testing.data', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "\n",
    "        train_data = self.train_data_df.to_numpy()\n",
    "        test_data = self.test_data_df.to_numpy()\n",
    "\n",
    "        train_rows_to_keep = [not ('?' in row) for row in train_data]\n",
    "        test_rows_to_keep = [not ('?' in row) for row in test_data]\n",
    "\n",
    "        train_data = train_data[train_rows_to_keep]\n",
    "        test_data = test_data[test_rows_to_keep]\n",
    "\n",
    "        # remove the annoying dot from the test labels\n",
    "        for row in test_data:\n",
    "            # print(len(row))\n",
    "            # print(row[-1])\n",
    "\n",
    "            row[-1] = row[-1][:-1]\n",
    "\n",
    "        # convert to numeric features\n",
    "        train_data_num = to_numeric(train_data, self.features, label=self.label, single_bit_binary=self.single_bit_binary)\n",
    "        test_data_num = to_numeric(test_data, self.features, label=self.label, single_bit_binary=self.single_bit_binary)\n",
    "\n",
    "        # split features and labels\n",
    "        Xtrain, Xtest = train_data_num[:, :-1].astype(np.float32), test_data_num[:, :-1].astype(np.float32)\n",
    "        ytrain, ytest = train_data_num[:, -1].astype(np.float32), test_data_num[:, -1].astype(np.float32)\n",
    "\n",
    "        print(name_state,len(Xtrain))\n",
    "        print(\"ytrain\",np.unique(ytrain))\n",
    "        print(\"ytest\",np.unique(ytest))\n",
    "        \n",
    "        self.num_features = Xtrain.shape[1]\n",
    "\n",
    "        # transfer to torch\n",
    "        self.Xtrain, self.Xtest = torch.tensor(Xtrain).to(self.device), torch.tensor(Xtest).to(self.device)\n",
    "        self.ytrain, self.ytest = torch.tensor(ytrain, dtype=torch.long).to(self.device), torch.tensor(ytest, dtype=torch.long).to(self.device)\n",
    "\n",
    "        # set to train mode as base\n",
    "        self.train()\n",
    "\n",
    "        # calculate the standardization statistics\n",
    "        self._calculate_mean_std()\n",
    "\n",
    "        # calculate the histograms and feature bounds\n",
    "        self._calculate_categorical_feature_distributions_and_continuous_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaad1865-8322-415e-bda3-82304b7ca884",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_codes = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "               \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "               \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "               \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "               \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "# state_codes=[\"AK\"]\n",
    "# state_codes=[\"BM\",\"BW\",\"WM\",\"WW\"]\n",
    "# state_codes=[\"men\",\"women\",\"white\",\"black\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6f1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaabc1f-3610-4984-a51d-7949207b56bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "278da44e",
   "metadata": {},
   "source": [
    "# pytorch 2.3 Loader -- SubGroup Processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131d1d8-1049-42b0-8608-9fa0a3970a3c",
   "metadata": {},
   "source": [
    "### all 166k data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f1d4b9-e9a2-4626-947e-40c85b7f27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA\n",
      "CA 166771\n",
      "ytrain [0. 1.]\n",
      "ytest [0.]\n"
     ]
    }
   ],
   "source": [
    "adult_dataset = ADULT(name_state=\"CA\")\n",
    "adult_dataset.standardize()\n",
    "dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "with open(f'50_clients_data/client_subG_processed/testing_all.pkl', 'wb') as f:\n",
    "    pickle.dump(dataloader, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e68c0c1-4b99-4957-9c01-5085377ace1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '50_clients_data/client_subG_splits/testing.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state_code \u001b[38;5;129;01min\u001b[39;00m state_codes:\n\u001b[1;32m      2\u001b[0m     state_name\u001b[38;5;241m=\u001b[39mstate_code\n\u001b[0;32m----> 3\u001b[0m     adult_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mADULT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     adult_dataset\u001b[38;5;241m.\u001b[39mstandardize()\n\u001b[1;32m      5\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m TensorDataset(adult_dataset\u001b[38;5;241m.\u001b[39mXtrain, adult_dataset\u001b[38;5;241m.\u001b[39mytrain)\n",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m, in \u001b[0;36mADULT.__init__\u001b[0;34m(self, name, single_bit_binary, device, random_state, name_state)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50_clients_data/client_subG_splits/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_state\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.data\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mkeys()), engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)        \n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50_clients_data/client_subG_splits/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_state\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.test\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mkeys()), skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m50_clients_data/client_subG_splits/testing.data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m        \n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50_clients_data/client_subG_splits/testing.test\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mkeys()), skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data_df\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv_torch2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv_torch2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv_torch2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv_torch2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv_torch2/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '50_clients_data/client_subG_splits/testing.data'"
     ]
    }
   ],
   "source": [
    "# for state_code in state_codes:\n",
    "#     state_name=state_code\n",
    "#     adult_dataset = ADULT(name_state=state_name)\n",
    "#     adult_dataset.standardize()\n",
    "#     dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "#     dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "#     with open(f'50_clients_data/client_subG_processed/testing_all.pkl', 'wb') as f:\n",
    "#         pickle.dump(dataloader, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4c674-ec48-4e42-aeec-d58121c96c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd738f-cdbb-448b-9a5d-7d38d1874681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016e3c7-2705-4cab-860d-4ec25ec23c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd11ef7-a4cc-47e3-b44a-cdcc085aa48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e7f8e02-f740-46a5-bd1c-2a70920fd18b",
   "metadata": {},
   "source": [
    "# only for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3477ce61-d42c-407e-940f-05c0807a624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM\n",
      "BM 76\n",
      "ytrain [0. 1.]\n",
      "ytest [0. 1.]\n",
      "BW\n",
      "BW 107\n",
      "ytrain [0. 1.]\n",
      "ytest []\n",
      "WM\n",
      "WM 592\n",
      "ytrain [0. 1.]\n",
      "ytest [0. 1.]\n",
      "WW\n",
      "WW 570\n",
      "ytrain [0. 1.]\n",
      "ytest [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for state_code in state_codes:\n",
    "    state_name=state_code\n",
    "    adult_dataset = ADULT(name_state=state_name)\n",
    "    adult_dataset.standardize()\n",
    "    dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "    with open(f'50_clients_data/client_subG_processed/{state_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)\n",
    "        \n",
    "    # dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "    # dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "    \n",
    "    # with open(f'50_clients_data/client_subG_processed/{state_name}_test.pkl', 'wb') as f:\n",
    "    #     pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf28d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4055.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5160.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2545.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5110.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3603.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4437 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  RAC1P  PINCP\n",
       "0     24.0  1.0  19.0  5.0   520.0   26.0  12.0  30.0  2.0    1.0  <=50K\n",
       "1     41.0  5.0  22.0  3.0  2360.0   36.0   0.0  40.0  2.0    1.0   >50K\n",
       "2     68.0  1.0  19.0  2.0  4055.0   36.0   0.0  20.0  2.0    1.0  <=50K\n",
       "3     54.0  1.0  21.0  1.0   705.0   36.0   1.0  50.0  2.0    1.0   >50K\n",
       "4     63.0  2.0  16.0  1.0  5160.0   36.0   1.0  40.0  2.0    1.0   >50K\n",
       "...    ...  ...   ...  ...     ...    ...   ...   ...  ...    ...    ...\n",
       "4432  26.0  1.0  11.0  1.0  2545.0   36.0   1.0   1.0  2.0    1.0  <=50K\n",
       "4433  54.0  1.0  19.0  1.0  5110.0   36.0   0.0  37.0  2.0    1.0  <=50K\n",
       "4434  23.0  1.0  21.0  5.0   540.0   36.0  15.0  40.0  2.0    1.0  <=50K\n",
       "4435  56.0  1.0  17.0  4.0  3603.0   36.0   0.0  38.0  2.0    1.0  <=50K\n",
       "4436  38.0  2.0  22.0  1.0  5340.0  163.0   1.0  40.0  2.0    1.0  <=50K\n",
       "\n",
       "[4437 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_dataset.train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e746fecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_name=\"male\"\n",
    "client_data_dir=\"50_clients_data/client_subG_processed/\"\n",
    "\n",
    "with open(client_data_dir+f'{state_name}.pkl', 'rb') as f:\n",
    "    train_data_all_client  = pickle.load(f)\n",
    "\n",
    "len(train_data_all_client)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85a7760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.standardize()\n",
    "# adult_dataset.Xtest\n",
    "\n",
    "# # SEX, RAC1P are same... thats why its 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b399a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.Xtest[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a2aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.de_standardize()\n",
    "# adult_dataset.Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73b6b814-f7b4-440b-a201-19fcd3279ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state_code in state_codes:\n",
    "#     state_name=state_code\n",
    "#     adult_dataset = ADULT(name_state=state_name)\n",
    "#     adult_dataset.standardize()\n",
    "#     dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "#     dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "#     with open(f'50_clients_data/processed_data/{state_name}.pkl', 'wb') as f:\n",
    "#         pickle.dump(dataloader, f)\n",
    "        \n",
    "#     dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "#     dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "    \n",
    "#     with open(f'50_clients_data/processed_data/{state_name}_test.pkl', 'wb') as f:\n",
    "#         pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ef5cb-74a0-4033-a2fc-3172210a75e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dc00f21-4b92-4079-bdbb-40274a50b82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_name=\"WM\"\n",
    "\n",
    "client_data_dir=\"50_clients_data/client_subG_processed/\"\n",
    "\n",
    "with open(client_data_dir+f'{state_name}.pkl', 'rb') as f:\n",
    "    train_data_all_client  = pickle.load(f)\n",
    "\n",
    "len(train_data_all_client)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7eddfd-e8a9-4e03-a822-b198284c537d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430fbbf3-4112-4b0f-9723-d6471e6251e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_name=state_code\n",
    "# adult_dataset = ADULT(name_state=state_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8ae69e-fc5b-4b41-adfd-49c9f8d6b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce26346e-4df0-4b96-bef1-f3e2883f7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult_dataset.Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ba364-92a2-443f-947b-db96d3fba52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b37538d-b8ef-48fa-9d01-cce848dde54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "# with open(f'50_clients_data/processed_data/{sta_name}.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataloader, f)\n",
    "\n",
    "\n",
    "# dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "# with open(f'50_clients_data/processed_data/{sta_name}_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b022b-9976-4d40-9760-41d7b59c8826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afaa707-b7c5-43db-9ca6-bfbfa772ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('50_clients_data/processed_data/AL.pkl', 'rb') as f:\n",
    "    dfs_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0a962-a7ff-47ec-9c6b-bfa51d6eb27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d223db8-45dc-473e-a9c8-25466aa142ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a93aad86-252d-4a8c-a4f6-661ca48862e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state_code, (features, label) in dfs.items():\n",
    "#     # take 30%\n",
    "#     num_rows_to_keep = int(len(features) * 0.3) \n",
    "#     random_indices = np.random.choice(len(features), num_rows_to_keep, replace=False)\n",
    "#     reduced_features = features.iloc[random_indices]\n",
    "#     reduced_label = label.iloc[random_indices]\n",
    "#     dfs[state_code] = (reduced_features, reduced_label)\n",
    "\n",
    "# for state_code, (reduced_features, reduced_label) in dfs.items():\n",
    "#     print(f\"State: {state_code}, Reduced Features Length: {len(reduced_features)}, Reduced Label Length: {len(reduced_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a55148d4-3246-4808-ad56-98a288027ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save the dictionary to a file\n",
    "# with open('dfs.pickle', 'wb') as f:\n",
    "#     pickle.dump(merge_dfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c36daf13-b0c9-443d-893f-48b468e56723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dfs.pickle', 'rb') as f:\n",
    "#     dfs_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "869ef307-92e7-481b-98a0-bb2f0f8e4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state_code, df in dfs_loaded.items():\n",
    "#     print(f\"State: {state_code}, df Length: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a2d099-4666-42e0-8243-db5888c33c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_loaded[\"TX\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e7e84-6d73-4379-abdb-89054d2141a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
