{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3114ee-6e82-4628-b63c-ce883d38c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets.base_dataset import BaseDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "from utils import to_numeric\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9d8762-ee6c-4e96-bbe2-672cc8db72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753155c1-cb5c-446a-8beb-b3156621d1ca",
   "metadata": {},
   "source": [
    "# data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc54549-b4e9-428a-a889-960846bb77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_codes = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n",
    "               \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n",
    "               \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "               \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n",
    "               \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "\n",
    "dfs = {}\n",
    "for state_code in state_codes:\n",
    "    acs_data = data_source.get_data(states=[state_code],download=True)\n",
    "    features, label, group = ACSIncome.df_to_pandas(acs_data)\n",
    "    dfs[state_code] = (features, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405da338-cd8e-49ab-b1bb-829519c63521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: AL, Features Length: 22268, Label Length: 22268\n",
      "State: AK, Features Length: 3546, Label Length: 3546\n",
      "State: AZ, Features Length: 33277, Label Length: 33277\n",
      "State: AR, Features Length: 13929, Label Length: 13929\n",
      "State: CA, Features Length: 195665, Label Length: 195665\n",
      "State: CO, Features Length: 31306, Label Length: 31306\n",
      "State: CT, Features Length: 19785, Label Length: 19785\n",
      "State: DE, Features Length: 4713, Label Length: 4713\n",
      "State: FL, Features Length: 98925, Label Length: 98925\n",
      "State: GA, Features Length: 50915, Label Length: 50915\n",
      "State: HI, Features Length: 7731, Label Length: 7731\n",
      "State: ID, Features Length: 8265, Label Length: 8265\n",
      "State: IL, Features Length: 67016, Label Length: 67016\n",
      "State: IN, Features Length: 35022, Label Length: 35022\n",
      "State: IA, Features Length: 17745, Label Length: 17745\n",
      "State: KS, Features Length: 15807, Label Length: 15807\n",
      "State: KY, Features Length: 22006, Label Length: 22006\n",
      "State: LA, Features Length: 20667, Label Length: 20667\n",
      "State: ME, Features Length: 7002, Label Length: 7002\n",
      "State: MD, Features Length: 33042, Label Length: 33042\n",
      "State: MA, Features Length: 40114, Label Length: 40114\n",
      "State: MI, Features Length: 50008, Label Length: 50008\n",
      "State: MN, Features Length: 31021, Label Length: 31021\n",
      "State: MS, Features Length: 13189, Label Length: 13189\n",
      "State: MO, Features Length: 31664, Label Length: 31664\n",
      "State: MT, Features Length: 5463, Label Length: 5463\n",
      "State: NE, Features Length: 10785, Label Length: 10785\n",
      "State: NV, Features Length: 14807, Label Length: 14807\n",
      "State: NH, Features Length: 7966, Label Length: 7966\n",
      "State: NJ, Features Length: 47781, Label Length: 47781\n",
      "State: NM, Features Length: 8711, Label Length: 8711\n",
      "State: NY, Features Length: 103021, Label Length: 103021\n",
      "State: NC, Features Length: 52067, Label Length: 52067\n",
      "State: ND, Features Length: 4455, Label Length: 4455\n",
      "State: OH, Features Length: 62135, Label Length: 62135\n",
      "State: OK, Features Length: 17917, Label Length: 17917\n",
      "State: OR, Features Length: 21919, Label Length: 21919\n",
      "State: PA, Features Length: 68308, Label Length: 68308\n",
      "State: RI, Features Length: 5712, Label Length: 5712\n",
      "State: SC, Features Length: 24879, Label Length: 24879\n",
      "State: SD, Features Length: 4899, Label Length: 4899\n",
      "State: TN, Features Length: 34003, Label Length: 34003\n",
      "State: TX, Features Length: 135924, Label Length: 135924\n",
      "State: UT, Features Length: 16337, Label Length: 16337\n",
      "State: VT, Features Length: 3767, Label Length: 3767\n",
      "State: VA, Features Length: 46144, Label Length: 46144\n",
      "State: WA, Features Length: 39944, Label Length: 39944\n",
      "State: WV, Features Length: 8103, Label Length: 8103\n",
      "State: WI, Features Length: 32690, Label Length: 32690\n",
      "State: WY, Features Length: 3064, Label Length: 3064\n"
     ]
    }
   ],
   "source": [
    "all_len=[]\n",
    "for state_code, (features, label) in dfs.items():\n",
    "    all_len.append(len(label))\n",
    "    print(f\"State: {state_code}, Features Length: {len(features)}, Label Length: {len(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a04cd85-a0e2-4c0a-8efa-2dec98583eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22268\n",
      "rare_combinations: 4\n",
      "22264\n",
      "3546\n",
      "rare_combinations: 5\n",
      "3541\n",
      "33277\n",
      "rare_combinations: 0\n",
      "33277\n",
      "13929\n",
      "rare_combinations: 2\n",
      "13927\n",
      "195665\n",
      "rare_combinations: 0\n",
      "195665\n",
      "31306\n",
      "rare_combinations: 1\n",
      "31305\n",
      "19785\n",
      "rare_combinations: 2\n",
      "19783\n",
      "4713\n",
      "rare_combinations: 5\n",
      "4708\n",
      "98925\n",
      "rare_combinations: 1\n",
      "98924\n",
      "50915\n",
      "rare_combinations: 3\n",
      "50912\n",
      "7731\n",
      "rare_combinations: 4\n",
      "7727\n",
      "8265\n",
      "rare_combinations: 6\n",
      "8259\n",
      "67016\n",
      "rare_combinations: 0\n",
      "67016\n",
      "35022\n",
      "rare_combinations: 1\n",
      "35021\n",
      "17745\n",
      "rare_combinations: 5\n",
      "17740\n",
      "15807\n",
      "rare_combinations: 6\n",
      "15801\n",
      "22006\n",
      "rare_combinations: 7\n",
      "21999\n",
      "20667\n",
      "rare_combinations: 5\n",
      "20662\n",
      "7002\n",
      "rare_combinations: 6\n",
      "6996\n",
      "33042\n",
      "rare_combinations: 1\n",
      "33041\n",
      "40114\n",
      "rare_combinations: 0\n",
      "40114\n",
      "50008\n",
      "rare_combinations: 1\n",
      "50007\n",
      "31021\n",
      "rare_combinations: 3\n",
      "31018\n",
      "13189\n",
      "rare_combinations: 6\n",
      "13183\n",
      "31664\n",
      "rare_combinations: 2\n",
      "31662\n",
      "5463\n",
      "rare_combinations: 11\n",
      "5452\n",
      "10785\n",
      "rare_combinations: 5\n",
      "10780\n",
      "14807\n",
      "rare_combinations: 6\n",
      "14801\n",
      "7966\n",
      "rare_combinations: 4\n",
      "7962\n",
      "47781\n",
      "rare_combinations: 0\n",
      "47781\n",
      "8711\n",
      "rare_combinations: 9\n",
      "8702\n",
      "103021\n",
      "rare_combinations: 0\n",
      "103021\n",
      "52067\n",
      "rare_combinations: 2\n",
      "52065\n",
      "4455\n",
      "rare_combinations: 7\n",
      "4448\n",
      "62135\n",
      "rare_combinations: 2\n",
      "62133\n",
      "17917\n",
      "rare_combinations: 2\n",
      "17915\n",
      "21919\n",
      "rare_combinations: 3\n",
      "21916\n",
      "68308\n",
      "rare_combinations: 2\n",
      "68306\n",
      "5712\n",
      "rare_combinations: 5\n",
      "5707\n",
      "24879\n",
      "rare_combinations: 2\n",
      "24877\n",
      "4899\n",
      "rare_combinations: 10\n",
      "4889\n",
      "34003\n",
      "rare_combinations: 5\n",
      "33998\n",
      "135924\n",
      "rare_combinations: 0\n",
      "135924\n",
      "16337\n",
      "rare_combinations: 5\n",
      "16332\n",
      "3767\n",
      "rare_combinations: 7\n",
      "3760\n",
      "46144\n",
      "rare_combinations: 1\n",
      "46143\n",
      "39944\n",
      "rare_combinations: 0\n",
      "39944\n",
      "8103\n",
      "rare_combinations: 7\n",
      "8096\n",
      "32690\n",
      "rare_combinations: 0\n",
      "32690\n",
      "3064\n",
      "rare_combinations: 10\n",
      "3054\n",
      "State: AL, df Length: 500, Label Counts: {'<=50K': 347, '>50K': 153}\n",
      "State: AK, df Length: 500, Label Counts: {'<=50K': 307, '>50K': 193}\n",
      "State: AZ, df Length: 500, Label Counts: {'<=50K': 333, '>50K': 167}\n",
      "State: AR, df Length: 500, Label Counts: {'<=50K': 369, '>50K': 131}\n",
      "State: CA, df Length: 500, Label Counts: {'<=50K': 295, '>50K': 205}\n",
      "State: CO, df Length: 500, Label Counts: {'<=50K': 294, '>50K': 206}\n",
      "State: CT, df Length: 500, Label Counts: {'<=50K': 263, '>50K': 237}\n",
      "State: DE, df Length: 500, Label Counts: {'<=50K': 306, '>50K': 194}\n",
      "State: FL, df Length: 500, Label Counts: {'<=50K': 336, '>50K': 164}\n",
      "State: GA, df Length: 500, Label Counts: {'<=50K': 325, '>50K': 175}\n",
      "State: HI, df Length: 500, Label Counts: {'<=50K': 311, '>50K': 189}\n",
      "State: ID, df Length: 500, Label Counts: {'<=50K': 359, '>50K': 141}\n",
      "State: IL, df Length: 500, Label Counts: {'<=50K': 305, '>50K': 195}\n",
      "State: IN, df Length: 500, Label Counts: {'<=50K': 349, '>50K': 151}\n",
      "State: IA, df Length: 500, Label Counts: {'<=50K': 347, '>50K': 153}\n",
      "State: KS, df Length: 500, Label Counts: {'<=50K': 346, '>50K': 154}\n",
      "State: KY, df Length: 500, Label Counts: {'<=50K': 346, '>50K': 154}\n",
      "State: LA, df Length: 500, Label Counts: {'<=50K': 336, '>50K': 164}\n",
      "State: ME, df Length: 500, Label Counts: {'<=50K': 350, '>50K': 150}\n",
      "State: MD, df Length: 500, Label Counts: {'<=50K': 258, '>50K': 242}\n",
      "State: MA, df Length: 500, Label Counts: {'<=50K': 266, '>50K': 234}\n",
      "State: MI, df Length: 500, Label Counts: {'<=50K': 335, '>50K': 165}\n",
      "State: MN, df Length: 500, Label Counts: {'<=50K': 316, '>50K': 184}\n",
      "State: MS, df Length: 500, Label Counts: {'<=50K': 368, '>50K': 132}\n",
      "State: MO, df Length: 500, Label Counts: {'<=50K': 347, '>50K': 153}\n",
      "State: MT, df Length: 500, Label Counts: {'<=50K': 356, '>50K': 144}\n",
      "State: NE, df Length: 500, Label Counts: {'<=50K': 344, '>50K': 156}\n",
      "State: NV, df Length: 500, Label Counts: {'<=50K': 333, '>50K': 167}\n",
      "State: NH, df Length: 500, Label Counts: {'<=50K': 302, '>50K': 198}\n",
      "State: NJ, df Length: 500, Label Counts: {'<=50K': 257, '>50K': 243}\n",
      "State: NM, df Length: 500, Label Counts: {'<=50K': 353, '>50K': 147}\n",
      "State: NY, df Length: 500, Label Counts: {'<=50K': 294, '>50K': 206}\n",
      "State: NC, df Length: 500, Label Counts: {'<=50K': 339, '>50K': 161}\n",
      "State: ND, df Length: 500, Label Counts: {'<=50K': 317, '>50K': 183}\n",
      "State: OH, df Length: 500, Label Counts: {'<=50K': 332, '>50K': 168}\n",
      "State: OK, df Length: 500, Label Counts: {'<=50K': 359, '>50K': 141}\n",
      "State: OR, df Length: 500, Label Counts: {'<=50K': 320, '>50K': 180}\n",
      "State: PA, df Length: 500, Label Counts: {'<=50K': 323, '>50K': 177}\n",
      "State: RI, df Length: 500, Label Counts: {'<=50K': 291, '>50K': 209}\n",
      "State: SC, df Length: 500, Label Counts: {'<=50K': 349, '>50K': 151}\n",
      "State: SD, df Length: 500, Label Counts: {'<=50K': 365, '>50K': 135}\n",
      "State: TN, df Length: 500, Label Counts: {'<=50K': 349, '>50K': 151}\n",
      "State: TX, df Length: 500, Label Counts: {'<=50K': 321, '>50K': 179}\n",
      "State: UT, df Length: 500, Label Counts: {'<=50K': 336, '>50K': 164}\n",
      "State: VT, df Length: 500, Label Counts: {'<=50K': 328, '>50K': 172}\n",
      "State: VA, df Length: 500, Label Counts: {'<=50K': 284, '>50K': 216}\n",
      "State: WA, df Length: 500, Label Counts: {'<=50K': 288, '>50K': 212}\n",
      "State: WV, df Length: 500, Label Counts: {'<=50K': 357, '>50K': 143}\n",
      "State: WI, df Length: 500, Label Counts: {'<=50K': 331, '>50K': 169}\n",
      "State: WY, df Length: 500, Label Counts: {'<=50K': 320, '>50K': 180}\n"
     ]
    }
   ],
   "source": [
    "merge_dfs={}\n",
    "sample_size=500\n",
    "\n",
    "for state_code, (features, label) in dfs.items():   \n",
    "\n",
    "    merge_df = pd.concat([features, label], axis=1)\n",
    "    merge_df = merge_df.dropna()\n",
    "    print(len(merge_df))\n",
    "    merge_df['PINCP'] = merge_df['PINCP'].replace({True: '>50K', False: '<=50K'})\n",
    "\n",
    "    # Random sampling with maintaning the statistics \n",
    "    # merge_df['strat'] = merge_df['SEX'].astype(str) + '_' + merge_df['RELP'].astype(str)\n",
    "    merge_df['strat'] = merge_df['SEX'].astype(str) + '_' + merge_df['RELP'].astype(str) + '_' + merge_df['PINCP'].astype(str)\n",
    "    \n",
    "    # merge_df['strat'] = (\n",
    "    #     merge_df['COW'].astype(str) + '_' +\n",
    "    #     merge_df['MAR'].astype(str) + '_' +\n",
    "    #     merge_df['SEX'].astype(str) + '_' +\n",
    "    #     merge_df['RAC1P'].astype(str) + '_' +\n",
    "    #     merge_df['PINCP'].astype(str)\n",
    "    #     )\n",
    "\n",
    "    # Check for rare combinations (occur less than 2 times)\n",
    "    #     \n",
    "    \n",
    "    combination_counts = merge_df['strat'].value_counts()\n",
    "    rare_combinations = combination_counts[combination_counts < 2].index\n",
    "    # print(len(merge_df))\n",
    "    print(\"rare_combinations:\",len(rare_combinations))\n",
    "\n",
    "    # Remove rare combination:- E.g 2.0_14.0_False from FL\n",
    "    \n",
    "    merge_df = merge_df[~merge_df['strat'].isin(rare_combinations)]\n",
    "    print(len(merge_df))\n",
    "\n",
    "    sampled_df, _ = train_test_split(\n",
    "    merge_df,\n",
    "    train_size=sample_size,\n",
    "    stratify=merge_df['strat'],\n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "    sampled_df = sampled_df.drop('strat', axis=1)\n",
    "    sampled_df = sampled_df.reset_index(drop=True)\n",
    "\n",
    "    merge_dfs[state_code] = sampled_df\n",
    "    # merge_dfs[state_code] = merge_df\n",
    "    \n",
    "for state_code, df in merge_dfs.items():\n",
    "    label_counts = df['PINCP'].value_counts()\n",
    "    print(f\"State: {state_code}, df Length: {len(df)}, Label Counts: {label_counts.to_dict()}\")\n",
    "\n",
    "    # print(f\"State: {state_code}, df Length: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e312e85-d869-4900-b58c-1f0e8062e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat(merge_dfs.values(), keys=merge_dfs.keys(), names=['state_code', 'index'])\n",
    "\n",
    "final_data = final_data.reset_index()\n",
    "final_data=final_data.drop(columns=['state_code', 'index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ac70c94-810c-4a8b-822f-5d450db1a0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdf8e1-a58c-4970-8f86-20a877ae35d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d71e93-f14e-4e12-9d27-28df72756692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22218"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take only 1 and 2 \n",
    "final_data=final_data[(final_data['RAC1P'].isin([1, 2])) & (final_data['SEX'].isin([1, 2]))]\n",
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457ed65-0b0c-49c4-98b7-01aee85b275f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63a7a997-084f-4777-aa9e-46b38581ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8990.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9645.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  COW  SCHL  MAR    OCCP  POBP  RELP  WKHP  SEX  RAC1P  PINCP\n",
       "1  33.0  1.0  16.0  3.0  8990.0   1.0   0.0  40.0  1.0    1.0  <=50K\n",
       "2  76.0  1.0  16.0  1.0  4230.0   1.0   1.0  40.0  2.0    2.0  <=50K\n",
       "3  79.0  1.0   1.0  1.0  9645.0   1.0   0.0  20.0  2.0    1.0  <=50K\n",
       "4  33.0  1.0  18.0  1.0  1105.0   1.0   1.0  45.0  1.0    1.0   >50K\n",
       "5  45.0  1.0  12.0  3.0  4230.0   1.0   0.0  40.0  2.0    1.0  <=50K"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5581cb8-2077-4184-903b-0a9653174b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINCP\n",
       "<=50K    14253\n",
       ">50K      7965\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['PINCP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b704a276-7dee-4a80-89e2-1f13e455eae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX\n",
       "1.0    11600\n",
       "2.0    10618\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa873a45-e50f-4cd4-b3b9-2460d0fe9de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAC1P\n",
       "1.0    20304\n",
       "2.0     1914\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['RAC1P'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e9238-3841-4d23-9e00-16c6a6383967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cac76411-d748-4c41-8ddc-759c740c24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(final_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaf8ba57-a487-4e36-bb11-d37ecdd02bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(f'50_clients_data/raw_data/all_client_25K_data_train.data', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3c73c8c-6f9f-4c27-8f77-b4353c64b334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       AGEP  COW  SCHL  MAR    OCCP  POBP  RELP  WKHP  SEX  RAC1P   PINCP\n",
      "1845   65.0  3.0  22.0  1.0  2320.0   5.0   1.0  45.0  2.0    1.0   >50K.\n",
      "8801   25.0  1.0  21.0  5.0  7000.0  22.0   2.0  40.0  1.0    1.0  <=50K.\n",
      "11179  22.0  1.0  16.0  5.0  9645.0  27.0   2.0  50.0  1.0    1.0  <=50K.\n",
      "9005   64.0  1.0  16.0  3.0  9121.0  36.0   0.0  28.0  1.0    1.0  <=50K.\n",
      "11663  40.0  2.0  16.0  5.0  4010.0  28.0   2.0  40.0  1.0    2.0  <=50K.\n"
     ]
    }
   ],
   "source": [
    "test_data['PINCP'] = test_data['PINCP'].astype(str) + '.'\n",
    "print(test_data.head())\n",
    "\n",
    "test_data.to_csv(f'50_clients_data/raw_data/all_client_25K.test', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0896336-72a0-45ab-832a-6ef28676abfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79d5f437-6aa0-47d7-8370-b8fa9e06574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take BLACK AND WHITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1b546-a7c8-4c57-a54f-4491e6fbf1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36029fd-e815-44b3-b018-8ec050bfe629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac557a-de00-4a9b-87da-1fd07f17abf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130937e8-0925-411f-8e0e-5d01f568d66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6fa88a4-94cc-442c-8644-93c2f4f4b623",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e82aa0f-4c99-49c1-a0cb-def6ba773bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2314e3bc-2def-4245-bf60-c28e40a0895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADULT(BaseDataset):\n",
    "\n",
    "    def __init__(self, name='ADULT', single_bit_binary=False, device='cpu', random_state=42, name_state=\"AL\"):\n",
    "        super(ADULT, self).__init__(name=name, device=device, random_state=random_state)\n",
    "        print(name_state)\n",
    "        self.features = {\n",
    "            'AGEP': None,\n",
    "            'COW': None,\n",
    "            'SCHL': None,\n",
    "            'MAR': None,\n",
    "            'OCCP': None,\n",
    "            'POBP': None,\n",
    "            'RELP': None,\n",
    "            'WKHP': None,\n",
    "            'SEX': None,\n",
    "            'RAC1P': None,      \n",
    "            'PINCP': ['>50K', '<=50K']\n",
    "        }\n",
    "        \n",
    "        self.single_bit_binary = single_bit_binary\n",
    "        self.label = 'PINCP'\n",
    "\n",
    "        self.train_features = {key: self.features[key] for key in self.features.keys() if key != self.label}\n",
    "\n",
    "        # name_state=\"GA\"\n",
    "        print(\"Path is static\")\n",
    "        self.train_data_df = pd.read_csv(f'50_clients_data/raw_data/all_client_25K_data_train.data', delimiter=',', names=list(self.features.keys()), engine='python')\n",
    "        self.test_data_df = pd.read_csv(f'50_clients_data/raw_data/all_client_25K.test', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "\n",
    "        train_data = self.train_data_df.to_numpy()\n",
    "        test_data = self.test_data_df.to_numpy()\n",
    "\n",
    "        train_rows_to_keep = [not ('?' in row) for row in train_data]\n",
    "        test_rows_to_keep = [not ('?' in row) for row in test_data]\n",
    "\n",
    "        train_data = train_data[train_rows_to_keep]\n",
    "        test_data = test_data[test_rows_to_keep]\n",
    "\n",
    "        # remove the annoying dot from the test labels\n",
    "        for row in test_data:\n",
    "            # print(len(row))\n",
    "            # print(row[-1])\n",
    "\n",
    "            row[-1] = row[-1][:-1]\n",
    "\n",
    "        # convert to numeric features\n",
    "        train_data_num = to_numeric(train_data, self.features, label=self.label, single_bit_binary=self.single_bit_binary)\n",
    "        test_data_num = to_numeric(test_data, self.features, label=self.label, single_bit_binary=self.single_bit_binary)\n",
    "\n",
    "        # split features and labels\n",
    "        Xtrain, Xtest = train_data_num[:, :-1].astype(np.float32), test_data_num[:, :-1].astype(np.float32)\n",
    "        ytrain, ytest = train_data_num[:, -1].astype(np.float32), test_data_num[:, -1].astype(np.float32)\n",
    "\n",
    "        print(name_state,len(Xtrain))\n",
    "        print(\"ytrain \",np.unique(ytrain))\n",
    "        print(\"ytest \",np.unique(ytest))\n",
    "        \n",
    "        self.num_features = Xtrain.shape[1]\n",
    "\n",
    "        # transfer to torch\n",
    "        self.Xtrain, self.Xtest = torch.tensor(Xtrain).to(self.device), torch.tensor(Xtest).to(self.device)\n",
    "        self.ytrain, self.ytest = torch.tensor(ytrain, dtype=torch.long).to(self.device), torch.tensor(ytest, dtype=torch.long).to(self.device)\n",
    "\n",
    "        # set to train mode as base\n",
    "        self.train()\n",
    "\n",
    "        # calculate the standardization statistics\n",
    "        self._calculate_mean_std()\n",
    "\n",
    "        # calculate the histograms and feature bounds\n",
    "        self._calculate_categorical_feature_distributions_and_continuous_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0acc5e40-1d09-4b9e-8b82-e1b60a00f621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL\n",
      "Path is static\n",
      "AL 17774\n",
      "ytrain  [0. 1.]\n",
      "ytest  [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "adult_dataset = ADULT()\n",
    "adult_dataset.standardize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53f8a158-d45e-411e-8187-d21cf2379b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "with open(f'50_clients_data/processed_data/all_client_25K_train.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)\n",
    "\n",
    "dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "with open(f'50_clients_data/processed_data/all_client_25K_test.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e2861-4ade-4e1d-abd4-9451e02107ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2aa67f4-ce19-4349-b92b-6a10f614f28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    0: >50k\\n    1: <=50k\\n    \\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    0: >50k\n",
    "    1: <=50k\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94c65772-5532-4e56-bdbb-957144d8cb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([1574, 2869]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(adult_dataset.ytest, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aff57cfc-6ac9-416e-a279-7943578264da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([ 6390, 11384]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(adult_dataset.ytrain, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7339e60d-7c1b-4b24-8992-842558f4883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_dataset.de_standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cc5cade-b75e-43d9-8926-7bdb10f63e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 0, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_dataset.ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b6c02-b1b4-4700-8319-f03dca46753f",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c87f6bb-41d0-4a1a-9b97-5370f27f9df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec13cfc-5071-47a1-a05f-32beafe910b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReLU(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    A linear layer followed by a ReLU activation layer.\n",
    "    \"\"\"    \n",
    "    \n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(LinReLU, self).__init__()      \n",
    "        linear = nn.Linear(in_size, out_size)\n",
    "        ReLU = nn.ReLU()\n",
    "        # self.Dropout = nn.Dropout(0.25)\n",
    "        self.layers = nn.Sequential(linear, ReLU)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.layers[0].reset_parameters()\n",
    "        return self\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple fully connected neural network with ReLU activations.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, layout):\n",
    "\n",
    "        super(FullyConnected, self).__init__()\n",
    "        layers = [nn.Flatten()]  # does not play any role, but makes the code neater\n",
    "        prev_fc_size = input_size\n",
    "        for i, fc_size in enumerate(layout):\n",
    "            if i + 1 < len(layout):\n",
    "                layers += [LinReLU(prev_fc_size, fc_size)]\n",
    "            else:\n",
    "                layers += [nn.Linear(prev_fc_size, 1), nn.Sigmoid()]\n",
    "                # layers += [nn.Linear(prev_fc_size, fc_size)]\n",
    "            prev_fc_size = fc_size\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d90065-87af-4444-89ce-02fd82b742c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1facb02-8a84-468f-b3fa-9f7df3b826a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87925f7c-4c65-443c-9837-b98af675db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data_dir=\"50_clients_data/processed_data/\"\n",
    "\n",
    "layout = [100, 100, 2]\n",
    "batch_size = 32\n",
    "num_epochs = 10  \n",
    "input_dim = 10\n",
    "lr=0.01\n",
    "\n",
    "model = FullyConnected(input_dim, layout)\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fe4bf3d-3ac1-4890-a836-c4ede58db224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data points_ 17792\n"
     ]
    }
   ],
   "source": [
    "with open('50_clients_data/processed_data/all_client_25K_train.pkl', 'rb') as f:\n",
    "    train_data_all_client  = pickle.load(f)\n",
    "\n",
    "with open('50_clients_data/processed_data/all_client_25K_test.pkl', 'rb') as f:\n",
    "    test_data  = pickle.load(f)\n",
    "\n",
    "print(f\"all data points_\", len(train_data_all_client)*batch_size)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f250c588-870b-4363-9024-1ba9fabb0d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data points_ 17792\n",
      "Validation Loss: 0.4346, Validation Accuracy: 0.7907\n",
      "Validation Loss: 0.4289, Validation Accuracy: 0.7961\n",
      "Validation Loss: 0.4272, Validation Accuracy: 0.7943\n",
      "Validation Loss: 0.4266, Validation Accuracy: 0.7947\n",
      "Validation Loss: 0.4255, Validation Accuracy: 0.7950\n",
      "Validation Loss: 0.4319, Validation Accuracy: 0.7941\n",
      "Validation Loss: 0.4308, Validation Accuracy: 0.7945\n",
      "Validation Loss: 0.4276, Validation Accuracy: 0.7947\n",
      "Validation Loss: 0.4269, Validation Accuracy: 0.7952\n",
      "Validation Loss: 0.4310, Validation Accuracy: 0.7954\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gradients = [] \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_data_all_client:\n",
    "        labels=labels.unsqueeze(1).float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        batch_gradients = []\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            if param.grad is not None:\n",
    "                batch_gradients.append(param.grad.clone())\n",
    "        gradients.append(batch_gradients)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        predicted_classes = (outputs > 0.5).float()\n",
    "        correct += (predicted_classes == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_data_all_client)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    # print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "   \n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        for inputs, labels in test_data:\n",
    "            labels=labels.unsqueeze(1).float()\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "            predicted_classes = (outputs > 0.5).float()\n",
    "            val_correct += (predicted_classes == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            \n",
    "            # _, val_predicted = torch.max(outputs, 1)\n",
    "            # val_total += labels.size(0)\n",
    "            # val_correct += (val_predicted == labels).sum().item()\n",
    "    \n",
    "    val_epoch_loss = val_running_loss / len(test_data)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    model.train()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b5fec4-ae11-416f-9e33-259c81b72776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa866c-ba06-4961-be15-f679e2533b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23ecadfe-7cbe-414b-83f8-089abca39de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 50_clients_data/clients_trained_model/pre_trained_model.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# torch.save(gradients, 'AL_gradients.pth')\n",
    "\n",
    "model_path = f\"50_clients_data/clients_trained_model/pre_trained_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15370a-c1de-4033-b420-61c5c2e65c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637e0fb-2bd3-4a98-8347-6c7bac6805b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd7caf-cc96-4a77-a72b-7c15f91f4eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42d9a065-4458-4998-ba18-ad26d7385f45",
   "metadata": {},
   "source": [
    "# Transfer learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6acd2d7-f302-4887-a7e0-d54ae8106cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data_dir=\"50_clients_data/processed_data/\"\n",
    "model_path = f\"50_clients_data/clients_trained_model/pre_trained_model.pth\"\n",
    "\n",
    "layout = [100, 100, 2]\n",
    "batch_size = 32\n",
    "num_epochs = 10 \n",
    "input_dim = 10\n",
    "lr=0.01\n",
    "\n",
    "model = FullyConnected(input_dim, layout)\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db900c9-cf6a-4e9f-8ad7-1f45b746331e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21123058-6f95-47dd-8751-101a14c61bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8217f797-140b-4a40-8dd4-d57fc555d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tableak_FT/50_clients_data/processed_data/AZ.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91f7864-d769-48c2-a126-7d4fae4d2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data points_ 2848\n",
      "all data points_ 736\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('50_clients_data/processed_data/AK.pkl', 'rb') as f:\n",
    "    new_train_data_all_client  = pickle.load(f)\n",
    "\n",
    "with open('50_clients_data/processed_data/AK_test.pkl', 'rb') as f:\n",
    "    new_test_data  = pickle.load(f)\n",
    "\n",
    "print(f\"all data points_\", len(new_train_data_all_client)*batch_size)   \n",
    "\n",
    "\n",
    "print(f\"all data points_\", len(new_test_data)*batch_size)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e17b4d5-8b30-41da-8909-a4b37c61a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.0142, Training Accuracy: 0.8307\n",
      "Validation Loss: 1.9419, Validation Accuracy: 0.7634\n",
      "Epoch [2/10], Training Loss: 0.0142, Training Accuracy: 0.8350\n",
      "Validation Loss: 1.9615, Validation Accuracy: 0.7613\n",
      "Epoch [3/10], Training Loss: 0.0139, Training Accuracy: 0.8392\n",
      "Validation Loss: 1.9626, Validation Accuracy: 0.7602\n",
      "Epoch [4/10], Training Loss: 0.0134, Training Accuracy: 0.8378\n",
      "Validation Loss: 1.9960, Validation Accuracy: 0.7606\n",
      "Epoch [5/10], Training Loss: 0.0131, Training Accuracy: 0.8491\n",
      "Validation Loss: 2.0020, Validation Accuracy: 0.7599\n",
      "Epoch [6/10], Training Loss: 0.0132, Training Accuracy: 0.8547\n",
      "Validation Loss: 2.0300, Validation Accuracy: 0.7567\n",
      "Epoch [7/10], Training Loss: 0.0133, Training Accuracy: 0.8533\n",
      "Validation Loss: 2.0439, Validation Accuracy: 0.7595\n",
      "Epoch [8/10], Training Loss: 0.0124, Training Accuracy: 0.8561\n",
      "Validation Loss: 2.0553, Validation Accuracy: 0.7574\n",
      "Epoch [9/10], Training Loss: 0.0129, Training Accuracy: 0.8632\n",
      "Validation Loss: 2.0542, Validation Accuracy: 0.7606\n",
      "Epoch [10/10], Training Loss: 0.0124, Training Accuracy: 0.8674\n",
      "Validation Loss: 2.0830, Validation Accuracy: 0.7578\n"
     ]
    }
   ],
   "source": [
    "gradients = [] \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in new_test_data:\n",
    "        labels=labels.unsqueeze(1).float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        batch_gradients = []\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            if param.grad is not None:\n",
    "                batch_gradients.append(param.grad.clone())\n",
    "        gradients.append(batch_gradients)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        predicted_classes = (outputs > 0.5).float()\n",
    "        correct += (predicted_classes == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_data_all_client)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    # print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "   \n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        for inputs, labels in new_train_data_all_client:\n",
    "            labels=labels.unsqueeze(1).float()\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "            predicted_classes = (outputs > 0.5).float()\n",
    "            val_correct += (predicted_classes == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            \n",
    "            # _, val_predicted = torch.max(outputs, 1)\n",
    "            # val_total += labels.size(0)\n",
    "            # val_correct += (val_predicted == labels).sum().item()\n",
    "    \n",
    "    val_epoch_loss = val_running_loss / len(test_data)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    model.train()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32c21f-dfa0-40a4-b67a-12a46e3d1ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06092e7f-d53d-40c1-93bb-d45759b7bd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72dd5b-bdb0-4f7d-b895-14d2829439f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b3780-df7b-4dac-9c3b-fa8b3491d4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962f8c9-f6f8-4296-8277-1a74283ced97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5e033-1d92-4366-a0c8-37bd5c0fa66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
